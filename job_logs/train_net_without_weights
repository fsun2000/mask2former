Command Line Args: Namespace(config_file='configs/replica/semantic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_160k_res640.yaml', dist_url='tcp://127.0.0.1:55927', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '12', 'SOLVER.BASE_LR', '0.0005', 'SOLVER.MAX_ITER', '16000', 'OUTPUT_DIR', './output/swin_large_without_weights'], resume=False)
Loading config configs/replica/semantic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_160k_res640.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config configs/replica/semantic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_160k_res640.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config configs/replica/semantic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_160k_res640.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config configs/replica/semantic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_160k_res640.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config configs/replica/semantic-segmentation/swin/../Base-ADE20K-SemanticSegmentation.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config configs/replica/semantic-segmentation/swin/../Base-ADE20K-SemanticSegmentation.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config configs/replica/semantic-segmentation/swin/../Base-ADE20K-SemanticSegmentation.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config configs/replica/semantic-segmentation/swin/../Base-ADE20K-SemanticSegmentation.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
[32m[04/01 17:17:46 detectron2]: [0mRank of current process: 0. World size: 4
[32m[04/01 17:17:47 detectron2]: [0mEnvironment info:
----------------------  --------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.22.3
detectron2              0.6 @/home/fsun/mask2former/detectron2/detectron2
Compiler                GCC 8.3
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/fsun/.conda/envs/m2f/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA TITAN RTX (arch=7.5)
Driver version          470.103.01
CUDA_HOME               /sw/arch/Debian10/EB_production/2021/software/CUDA/11.3.1
Pillow                  9.0.1
torchvision             0.10.0 @/home/fsun/.conda/envs/m2f/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220305
iopath                  0.1.9
cv2                     4.5.5
----------------------  --------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2022.0-Product Build 20211112 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[32m[04/01 17:17:47 detectron2]: [0mCommand line arguments: Namespace(config_file='configs/replica/semantic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_160k_res640.yaml', dist_url='tcp://127.0.0.1:55927', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '12', 'SOLVER.BASE_LR', '0.0005', 'SOLVER.MAX_ITER', '16000', 'OUTPUT_DIR', './output/swin_large_without_weights'], resume=False)
[32m[04/01 17:17:47 detectron2]: [0mContents of args.config_file=configs/replica/semantic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_160k_res640.yaml:
_BASE_: ../maskformer2_R50_bs16_160k.yaml
MODEL:
  BACKBONE:
    NAME: "D2SwinTransformer"
  SWIN:
    EMBED_DIM: 192
    DEPTHS: [2, 2, 18, 2]
    NUM_HEADS: [6, 12, 24, 48]
    WINDOW_SIZE: 12
    APE: False
    DROP_PATH_RATE: 0.3
    PATCH_NORM: True
    PRETRAIN_IMG_SIZE: 384
  WEIGHTS: None #"swin_large_patch4_window12_384_22k.pkl"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
INPUT:
  MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 640) for x in range(5, 21)]"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 2560
  MAX_SIZE_TEST: 2560
  CROP:
    ENABLED: False # True
    TYPE: "absolute"
    SIZE: (512, 512) # (640, 640)
    SINGLE_CATEGORY_MAX_AREA: 1.0
  COLOR_AUG_SSD: True
  SIZE_DIVISIBILITY: 640  # used in dataset mapper
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False
    MIN_SIZES: [320, 480, 640, 800, 960, 1120]
    MAX_SIZE: 4480
    FLIP: True

[32m[04/01 17:17:47 detectron2]: [0mRunning with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - replica_sem_seg_val
  TRAIN:
  - replica_sem_seg_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: false
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 512
    - 512
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 2560
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  - 1024
  - 1088
  - 1152
  - 1216
  - 1280
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 640
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: D2SwinTransformer
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: false
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: true
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MaskFormer
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 1
    - 1
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: basic
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 0
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskFormerHead
    NORM: GN
    NUM_CLASSES: 30
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 192
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 6
    - 12
    - 24
    - 48
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 384
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 12
  WEIGHTS: null
OUTPUT_DIR: ./output/swin_large_without_weights
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0005
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 12
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 16000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4480
    MIN_SIZES:
    - 320
    - 480
    - 640
    - 800
    - 960
    - 1120
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[32m[04/01 17:17:47 detectron2]: [0mFull config saved to ./output/swin_large_without_weights/config.yaml
[32m[04/01 17:17:47 d2.utils.env]: [0mUsing a generated random seed 47763303
[32m[04/01 17:17:56 d2.engine.defaults]: [0mModel:
MaskFormer(
  (backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (6): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (7): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (8): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (9): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (10): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (11): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (12): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (13): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (14): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (15): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (16): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (17): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=3072, out_features=1536, bias=False)
          (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=1536, out_features=4608, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1536, out_features=1536, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1536, out_features=6144, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=6144, out_features=1536, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=1536, out_features=4608, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1536, out_features=1536, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1536, out_features=6144, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=6144, out_features=1536, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=31, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 30
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
[32m[04/01 17:17:56 mask2former.data.dataset_mappers.mask_former_semantic_dataset_mapper]: [0m[MaskFormerSemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=2560, sample_style='choice'), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x14e4b425b190>, RandomFlip()]
train_list /home/fsun/segfusion/lists/replica/lisa_train_small.txt
[32m[04/01 17:17:56 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/01 17:17:56 d2.data.common]: [0mSerializing 1546 elements to byte tensors and concatenating them all ...
[32m[04/01 17:17:56 d2.data.common]: [0mSerialized dataset takes 0.35 MiB
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
train_list /home/fsun/segfusion/lists/replica/lisa_train_small.txt
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
train_list /home/fsun/segfusion/lists/replica/lisa_train_small.txt
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
train_list /home/fsun/segfusion/lists/replica/lisa_train_small.txt
[32m[04/01 17:17:57 fvcore.common.checkpoint]: [0mNo checkpoint found. Initializing model from scratch
[32m[04/01 17:17:57 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/01 17:18:44 d2.utils.events]: [0m eta: 7:15:08  iter: 19  total_loss: 110.8  loss_ce: 4.112  loss_mask: 3.287  loss_dice: 4.287  loss_ce_0: 6.722  loss_mask_0: 1.803  loss_dice_0: 4.213  loss_ce_1: 3.844  loss_mask_1: 2.137  loss_dice_1: 4.22  loss_ce_2: 4.015  loss_mask_2: 2.655  loss_dice_2: 4.296  loss_ce_3: 4.044  loss_mask_3: 2.653  loss_dice_3: 4.306  loss_ce_4: 4.05  loss_mask_4: 2.875  loss_dice_4: 4.396  loss_ce_5: 4.072  loss_mask_5: 3.13  loss_dice_5: 4.346  loss_ce_6: 4.114  loss_mask_6: 3.261  loss_dice_6: 4.326  loss_ce_7: 4.101  loss_mask_7: 3.143  loss_dice_7: 4.345  loss_ce_8: 4.097  loss_mask_8: 3.527  loss_dice_8: 4.324  time: 1.8326  data_time: 0.4317  lr: 4.9947e-05  max_mem: 20947M
[32m[04/01 17:19:13 d2.utils.events]: [0m eta: 6:26:35  iter: 39  total_loss: 97.28  loss_ce: 3.578  loss_mask: 2.155  loss_dice: 4.455  loss_ce_0: 6.438  loss_mask_0: 1.536  loss_dice_0: 3.969  loss_ce_1: 2.415  loss_mask_1: 1.581  loss_dice_1: 3.978  loss_ce_2: 2.514  loss_mask_2: 1.627  loss_dice_2: 4.088  loss_ce_3: 2.895  loss_mask_3: 1.686  loss_dice_3: 4.101  loss_ce_4: 3.169  loss_mask_4: 1.833  loss_dice_4: 4.194  loss_ce_5: 3.452  loss_mask_5: 2.104  loss_dice_5: 4.394  loss_ce_6: 3.574  loss_mask_6: 2.205  loss_dice_6: 4.436  loss_ce_7: 3.571  loss_mask_7: 2.189  loss_dice_7: 4.44  loss_ce_8: 3.571  loss_mask_8: 2.166  loss_dice_8: 4.455  time: 1.6173  data_time: 0.0648  lr: 4.989e-05  max_mem: 20947M
[32m[04/01 17:19:37 d2.utils.events]: [0m eta: 6:20:33  iter: 59  total_loss: 91.81  loss_ce: 3.66  loss_mask: 2.113  loss_dice: 4.464  loss_ce_0: 6.171  loss_mask_0: 1.512  loss_dice_0: 3.782  loss_ce_1: 1.953  loss_mask_1: 1.691  loss_dice_1: 3.84  loss_ce_2: 2.063  loss_mask_2: 1.679  loss_dice_2: 3.866  loss_ce_3: 2.428  loss_mask_3: 1.68  loss_dice_3: 3.879  loss_ce_4: 2.726  loss_mask_4: 1.733  loss_dice_4: 3.857  loss_ce_5: 3.083  loss_mask_5: 1.679  loss_dice_5: 3.945  loss_ce_6: 3.482  loss_mask_6: 1.699  loss_dice_6: 4.118  loss_ce_7: 3.614  loss_mask_7: 1.904  loss_dice_7: 4.382  loss_ce_8: 3.648  loss_mask_8: 2.093  loss_dice_8: 4.487  time: 1.4847  data_time: 0.0602  lr: 4.9834e-05  max_mem: 20960M
[32m[04/01 17:19:59 d2.utils.events]: [0m eta: 6:11:34  iter: 79  total_loss: 83.34  loss_ce: 3.372  loss_mask: 1.705  loss_dice: 3.915  loss_ce_0: 5.969  loss_mask_0: 1.524  loss_dice_0: 3.478  loss_ce_1: 2.119  loss_mask_1: 1.628  loss_dice_1: 3.554  loss_ce_2: 2.306  loss_mask_2: 1.683  loss_dice_2: 3.47  loss_ce_3: 2.566  loss_mask_3: 1.718  loss_dice_3: 3.487  loss_ce_4: 2.715  loss_mask_4: 1.681  loss_dice_4: 3.531  loss_ce_5: 2.843  loss_mask_5: 1.699  loss_dice_5: 3.52  loss_ce_6: 2.973  loss_mask_6: 1.729  loss_dice_6: 3.516  loss_ce_7: 3.156  loss_mask_7: 1.674  loss_dice_7: 3.536  loss_ce_8: 3.319  loss_mask_8: 1.701  loss_dice_8: 3.668  time: 1.3786  data_time: 0.0764  lr: 4.9778e-05  max_mem: 20960M
[32m[04/01 17:20:20 d2.utils.events]: [0m eta: 4:51:42  iter: 99  total_loss: 81.01  loss_ce: 3.227  loss_mask: 1.626  loss_dice: 3.453  loss_ce_0: 5.751  loss_mask_0: 1.484  loss_dice_0: 3.262  loss_ce_1: 2.515  loss_mask_1: 1.516  loss_dice_1: 3.307  loss_ce_2: 2.68  loss_mask_2: 1.53  loss_dice_2: 3.294  loss_ce_3: 3.009  loss_mask_3: 1.52  loss_dice_3: 3.298  loss_ce_4: 3.055  loss_mask_4: 1.603  loss_dice_4: 3.305  loss_ce_5: 3.031  loss_mask_5: 1.634  loss_dice_5: 3.289  loss_ce_6: 3.046  loss_mask_6: 1.665  loss_dice_6: 3.274  loss_ce_7: 3.151  loss_mask_7: 1.62  loss_dice_7: 3.259  loss_ce_8: 3.157  loss_mask_8: 1.585  loss_dice_8: 3.361  time: 1.3137  data_time: 0.0682  lr: 4.9721e-05  max_mem: 20965M
[32m[04/01 17:20:42 d2.utils.events]: [0m eta: 4:49:17  iter: 119  total_loss: 84.57  loss_ce: 3.229  loss_mask: 1.639  loss_dice: 3.402  loss_ce_0: 5.624  loss_mask_0: 1.458  loss_dice_0: 3.251  loss_ce_1: 3.021  loss_mask_1: 1.477  loss_dice_1: 3.347  loss_ce_2: 3.331  loss_mask_2: 1.563  loss_dice_2: 3.365  loss_ce_3: 3.29  loss_mask_3: 1.5  loss_dice_3: 3.337  loss_ce_4: 3.101  loss_mask_4: 1.634  loss_dice_4: 3.507  loss_ce_5: 3.204  loss_mask_5: 1.611  loss_dice_5: 3.441  loss_ce_6: 3.184  loss_mask_6: 1.594  loss_dice_6: 3.381  loss_ce_7: 3.427  loss_mask_7: 1.613  loss_dice_7: 3.339  loss_ce_8: 3.297  loss_mask_8: 1.672  loss_dice_8: 3.325  time: 1.2756  data_time: 0.0711  lr: 4.9665e-05  max_mem: 20965M
[32m[04/01 17:21:04 d2.utils.events]: [0m eta: 4:47:04  iter: 139  total_loss: 79.64  loss_ce: 3.048  loss_mask: 1.536  loss_dice: 3.035  loss_ce_0: 5.584  loss_mask_0: 1.465  loss_dice_0: 3.053  loss_ce_1: 2.858  loss_mask_1: 1.566  loss_dice_1: 3.047  loss_ce_2: 3.122  loss_mask_2: 1.537  loss_dice_2: 3.189  loss_ce_3: 2.836  loss_mask_3: 1.644  loss_dice_3: 3.216  loss_ce_4: 2.984  loss_mask_4: 1.601  loss_dice_4: 3.111  loss_ce_5: 3.113  loss_mask_5: 1.617  loss_dice_5: 3.035  loss_ce_6: 3.092  loss_mask_6: 1.593  loss_dice_6: 3.191  loss_ce_7: 3.044  loss_mask_7: 1.644  loss_dice_7: 3.063  loss_ce_8: 3.086  loss_mask_8: 1.639  loss_dice_8: 3.077  time: 1.2461  data_time: 0.0568  lr: 4.9609e-05  max_mem: 20965M
[32m[04/01 17:21:25 d2.utils.events]: [0m eta: 4:45:22  iter: 159  total_loss: 81.19  loss_ce: 3.196  loss_mask: 1.632  loss_dice: 3.107  loss_ce_0: 5.445  loss_mask_0: 1.455  loss_dice_0: 3.108  loss_ce_1: 2.988  loss_mask_1: 1.51  loss_dice_1: 3.1  loss_ce_2: 3.114  loss_mask_2: 1.499  loss_dice_2: 3.117  loss_ce_3: 3.021  loss_mask_3: 1.736  loss_dice_3: 3.215  loss_ce_4: 3.143  loss_mask_4: 1.666  loss_dice_4: 3.219  loss_ce_5: 3.064  loss_mask_5: 1.738  loss_dice_5: 3.159  loss_ce_6: 3.188  loss_mask_6: 1.707  loss_dice_6: 3.133  loss_ce_7: 3.03  loss_mask_7: 1.645  loss_dice_7: 3.113  loss_ce_8: 3.133  loss_mask_8: 1.497  loss_dice_8: 3.097  time: 1.2226  data_time: 0.0617  lr: 4.9553e-05  max_mem: 20965M
[32m[04/01 17:21:46 d2.utils.events]: [0m eta: 4:44:04  iter: 179  total_loss: 81.22  loss_ce: 3.133  loss_mask: 1.543  loss_dice: 3.152  loss_ce_0: 5.347  loss_mask_0: 1.386  loss_dice_0: 3.1  loss_ce_1: 3.115  loss_mask_1: 1.401  loss_dice_1: 2.971  loss_ce_2: 3.247  loss_mask_2: 1.433  loss_dice_2: 2.937  loss_ce_3: 3.356  loss_mask_3: 1.479  loss_dice_3: 3.176  loss_ce_4: 3.202  loss_mask_4: 1.57  loss_dice_4: 3.226  loss_ce_5: 3.245  loss_mask_5: 1.545  loss_dice_5: 3.042  loss_ce_6: 3.387  loss_mask_6: 1.55  loss_dice_6: 3.125  loss_ce_7: 3.319  loss_mask_7: 1.481  loss_dice_7: 3.208  loss_ce_8: 3.146  loss_mask_8: 1.561  loss_dice_8: 3.131  time: 1.2032  data_time: 0.0515  lr: 4.9496e-05  max_mem: 20965M
[32m[04/01 17:22:07 d2.utils.events]: [0m eta: 4:43:42  iter: 199  total_loss: 82.44  loss_ce: 2.917  loss_mask: 1.579  loss_dice: 3.186  loss_ce_0: 5.253  loss_mask_0: 1.354  loss_dice_0: 3.1  loss_ce_1: 3.136  loss_mask_1: 1.463  loss_dice_1: 3.006  loss_ce_2: 3.259  loss_mask_2: 1.582  loss_dice_2: 3.125  loss_ce_3: 3.297  loss_mask_3: 1.615  loss_dice_3: 3.461  loss_ce_4: 3.12  loss_mask_4: 1.716  loss_dice_4: 3.306  loss_ce_5: 3.258  loss_mask_5: 1.542  loss_dice_5: 3.296  loss_ce_6: 3.235  loss_mask_6: 1.685  loss_dice_6: 3.308  loss_ce_7: 3.265  loss_mask_7: 1.572  loss_dice_7: 3.152  loss_ce_8: 3.225  loss_mask_8: 1.6  loss_dice_8: 3.237  time: 1.1891  data_time: 0.0661  lr: 4.944e-05  max_mem: 20965M
[32m[04/01 17:22:29 d2.utils.events]: [0m eta: 4:43:21  iter: 219  total_loss: 85.68  loss_ce: 3.278  loss_mask: 1.618  loss_dice: 3.222  loss_ce_0: 5.15  loss_mask_0: 1.431  loss_dice_0: 3.089  loss_ce_1: 3.169  loss_mask_1: 1.605  loss_dice_1: 2.973  loss_ce_2: 3.51  loss_mask_2: 1.597  loss_dice_2: 3.307  loss_ce_3: 3.347  loss_mask_3: 2.073  loss_dice_3: 3.743  loss_ce_4: 3.524  loss_mask_4: 1.786  loss_dice_4: 3.438  loss_ce_5: 3.416  loss_mask_5: 1.636  loss_dice_5: 3.303  loss_ce_6: 3.265  loss_mask_6: 1.59  loss_dice_6: 3.247  loss_ce_7: 3.332  loss_mask_7: 1.601  loss_dice_7: 3.191  loss_ce_8: 3.344  loss_mask_8: 1.584  loss_dice_8: 3.144  time: 1.1784  data_time: 0.0578  lr: 4.9384e-05  max_mem: 20965M
[32m[04/01 17:22:50 d2.utils.events]: [0m eta: 4:42:46  iter: 239  total_loss: 84.39  loss_ce: 2.981  loss_mask: 1.618  loss_dice: 3.19  loss_ce_0: 5.05  loss_mask_0: 1.421  loss_dice_0: 3.092  loss_ce_1: 3.062  loss_mask_1: 1.493  loss_dice_1: 2.988  loss_ce_2: 3.225  loss_mask_2: 1.538  loss_dice_2: 3.406  loss_ce_3: 3.217  loss_mask_3: 1.897  loss_dice_3: 3.726  loss_ce_4: 3.579  loss_mask_4: 1.785  loss_dice_4: 3.502  loss_ce_5: 3.392  loss_mask_5: 1.771  loss_dice_5: 3.439  loss_ce_6: 3.309  loss_mask_6: 1.753  loss_dice_6: 3.504  loss_ce_7: 3.256  loss_mask_7: 1.635  loss_dice_7: 3.294  loss_ce_8: 3.114  loss_mask_8: 1.617  loss_dice_8: 3.327  time: 1.1688  data_time: 0.0623  lr: 4.9327e-05  max_mem: 20965M
[32m[04/01 17:23:12 d2.utils.events]: [0m eta: 4:42:11  iter: 259  total_loss: 89.82  loss_ce: 3.082  loss_mask: 1.775  loss_dice: 3.586  loss_ce_0: 4.953  loss_mask_0: 1.449  loss_dice_0: 3.063  loss_ce_1: 3.001  loss_mask_1: 1.508  loss_dice_1: 2.993  loss_ce_2: 3.298  loss_mask_2: 1.549  loss_dice_2: 3.342  loss_ce_3: 4.064  loss_mask_3: 2.152  loss_dice_3: 3.866  loss_ce_4: 3.739  loss_mask_4: 2.231  loss_dice_4: 3.872  loss_ce_5: 3.521  loss_mask_5: 1.957  loss_dice_5: 3.63  loss_ce_6: 3.269  loss_mask_6: 1.886  loss_dice_6: 3.565  loss_ce_7: 3.262  loss_mask_7: 1.976  loss_dice_7: 3.478  loss_ce_8: 3.329  loss_mask_8: 1.842  loss_dice_8: 3.527  time: 1.1605  data_time: 0.0565  lr: 4.9271e-05  max_mem: 20965M
[32m[04/01 17:23:33 d2.utils.events]: [0m eta: 4:41:43  iter: 279  total_loss: 84.19  loss_ce: 3.165  loss_mask: 1.497  loss_dice: 2.991  loss_ce_0: 4.949  loss_mask_0: 1.376  loss_dice_0: 2.966  loss_ce_1: 2.997  loss_mask_1: 1.461  loss_dice_1: 3.014  loss_ce_2: 3.037  loss_mask_2: 1.593  loss_dice_2: 3.193  loss_ce_3: 3.576  loss_mask_3: 1.675  loss_dice_3: 3.701  loss_ce_4: 3.711  loss_mask_4: 1.728  loss_dice_4: 3.753  loss_ce_5: 3.352  loss_mask_5: 1.828  loss_dice_5: 3.605  loss_ce_6: 3.412  loss_mask_6: 1.662  loss_dice_6: 3.262  loss_ce_7: 3.285  loss_mask_7: 1.693  loss_dice_7: 3.359  loss_ce_8: 3.219  loss_mask_8: 1.595  loss_dice_8: 3.235  time: 1.1539  data_time: 0.0613  lr: 4.9215e-05  max_mem: 20965M
[32m[04/01 17:23:55 d2.utils.events]: [0m eta: 4:41:04  iter: 299  total_loss: 82.77  loss_ce: 3.043  loss_mask: 1.64  loss_dice: 3.012  loss_ce_0: 4.878  loss_mask_0: 1.501  loss_dice_0: 2.895  loss_ce_1: 3.104  loss_mask_1: 1.683  loss_dice_1: 2.957  loss_ce_2: 3.255  loss_mask_2: 1.607  loss_dice_2: 3.016  loss_ce_3: 3.432  loss_mask_3: 1.627  loss_dice_3: 3.439  loss_ce_4: 3.351  loss_mask_4: 1.649  loss_dice_4: 3.47  loss_ce_5: 3.237  loss_mask_5: 1.748  loss_dice_5: 3.384  loss_ce_6: 3.256  loss_mask_6: 1.721  loss_dice_6: 3.319  loss_ce_7: 3.132  loss_mask_7: 1.609  loss_dice_7: 3.119  loss_ce_8: 3.103  loss_mask_8: 1.671  loss_dice_8: 3.16  time: 1.1483  data_time: 0.0626  lr: 4.9158e-05  max_mem: 20965M
[32m[04/01 17:24:16 d2.utils.events]: [0m eta: 4:40:33  iter: 319  total_loss: 84.8  loss_ce: 3.217  loss_mask: 1.673  loss_dice: 3.303  loss_ce_0: 4.701  loss_mask_0: 1.406  loss_dice_0: 2.954  loss_ce_1: 2.976  loss_mask_1: 1.766  loss_dice_1: 3.253  loss_ce_2: 3.15  loss_mask_2: 1.666  loss_dice_2: 3.208  loss_ce_3: 3.399  loss_mask_3: 1.656  loss_dice_3: 3.526  loss_ce_4: 3.321  loss_mask_4: 1.553  loss_dice_4: 3.239  loss_ce_5: 3.241  loss_mask_5: 1.628  loss_dice_5: 3.425  loss_ce_6: 3.398  loss_mask_6: 1.711  loss_dice_6: 3.287  loss_ce_7: 3.376  loss_mask_7: 1.879  loss_dice_7: 3.317  loss_ce_8: 3.298  loss_mask_8: 1.666  loss_dice_8: 3.241  time: 1.1429  data_time: 0.0607  lr: 4.9102e-05  max_mem: 20965M
[32m[04/01 17:24:38 d2.utils.events]: [0m eta: 4:40:00  iter: 339  total_loss: 82.7  loss_ce: 3.462  loss_mask: 1.664  loss_dice: 3.378  loss_ce_0: 4.613  loss_mask_0: 1.392  loss_dice_0: 2.938  loss_ce_1: 3.207  loss_mask_1: 1.475  loss_dice_1: 2.837  loss_ce_2: 3.114  loss_mask_2: 1.48  loss_dice_2: 3.034  loss_ce_3: 3.427  loss_mask_3: 1.554  loss_dice_3: 3.454  loss_ce_4: 3.532  loss_mask_4: 1.687  loss_dice_4: 3.246  loss_ce_5: 3.405  loss_mask_5: 1.566  loss_dice_5: 3.327  loss_ce_6: 3.249  loss_mask_6: 1.797  loss_dice_6: 3.46  loss_ce_7: 3.124  loss_mask_7: 1.887  loss_dice_7: 3.367  loss_ce_8: 3.154  loss_mask_8: 1.576  loss_dice_8: 3.182  time: 1.1384  data_time: 0.0597  lr: 4.9046e-05  max_mem: 20965M
[32m[04/01 17:24:59 d2.utils.events]: [0m eta: 4:39:28  iter: 359  total_loss: 83.85  loss_ce: 3.291  loss_mask: 1.638  loss_dice: 3.283  loss_ce_0: 4.512  loss_mask_0: 1.429  loss_dice_0: 2.916  loss_ce_1: 3.098  loss_mask_1: 1.558  loss_dice_1: 2.808  loss_ce_2: 3.272  loss_mask_2: 1.489  loss_dice_2: 2.849  loss_ce_3: 3.423  loss_mask_3: 1.624  loss_dice_3: 3.445  loss_ce_4: 3.537  loss_mask_4: 1.887  loss_dice_4: 3.513  loss_ce_5: 3.326  loss_mask_5: 1.676  loss_dice_5: 3.4  loss_ce_6: 3.184  loss_mask_6: 1.968  loss_dice_6: 3.406  loss_ce_7: 3.276  loss_mask_7: 1.714  loss_dice_7: 3.173  loss_ce_8: 3.103  loss_mask_8: 1.688  loss_dice_8: 3.091  time: 1.1344  data_time: 0.0630  lr: 4.8989e-05  max_mem: 20965M
[32m[04/01 17:25:20 d2.utils.events]: [0m eta: 4:38:55  iter: 379  total_loss: 82.1  loss_ce: 3.188  loss_mask: 1.676  loss_dice: 3.24  loss_ce_0: 4.471  loss_mask_0: 1.303  loss_dice_0: 2.952  loss_ce_1: 3.022  loss_mask_1: 1.43  loss_dice_1: 2.865  loss_ce_2: 3.205  loss_mask_2: 1.413  loss_dice_2: 2.994  loss_ce_3: 3.391  loss_mask_3: 1.537  loss_dice_3: 3.396  loss_ce_4: 3.593  loss_mask_4: 1.668  loss_dice_4: 3.522  loss_ce_5: 3.385  loss_mask_5: 1.61  loss_dice_5: 3.351  loss_ce_6: 3.376  loss_mask_6: 1.715  loss_dice_6: 3.432  loss_ce_7: 3.393  loss_mask_7: 1.726  loss_dice_7: 3.146  loss_ce_8: 3.278  loss_mask_8: 1.566  loss_dice_8: 3.084  time: 1.1305  data_time: 0.0771  lr: 4.8933e-05  max_mem: 20965M
[32m[04/01 17:25:42 d2.utils.events]: [0m eta: 4:38:34  iter: 399  total_loss: 81.02  loss_ce: 3.237  loss_mask: 1.5  loss_dice: 3.187  loss_ce_0: 4.443  loss_mask_0: 1.367  loss_dice_0: 2.899  loss_ce_1: 3.072  loss_mask_1: 1.503  loss_dice_1: 2.864  loss_ce_2: 3.194  loss_mask_2: 1.498  loss_dice_2: 2.976  loss_ce_3: 3.438  loss_mask_3: 1.521  loss_dice_3: 3.282  loss_ce_4: 3.501  loss_mask_4: 1.581  loss_dice_4: 3.424  loss_ce_5: 3.434  loss_mask_5: 1.569  loss_dice_5: 3.284  loss_ce_6: 3.467  loss_mask_6: 1.626  loss_dice_6: 3.284  loss_ce_7: 3.257  loss_mask_7: 1.598  loss_dice_7: 3.108  loss_ce_8: 3.209  loss_mask_8: 1.501  loss_dice_8: 3.065  time: 1.1275  data_time: 0.0648  lr: 4.8876e-05  max_mem: 20965M
[32m[04/01 17:26:03 d2.utils.events]: [0m eta: 4:38:07  iter: 419  total_loss: 77.79  loss_ce: 2.91  loss_mask: 1.664  loss_dice: 2.868  loss_ce_0: 4.275  loss_mask_0: 1.353  loss_dice_0: 2.699  loss_ce_1: 2.815  loss_mask_1: 1.419  loss_dice_1: 2.656  loss_ce_2: 2.894  loss_mask_2: 1.462  loss_dice_2: 2.801  loss_ce_3: 3.179  loss_mask_3: 1.596  loss_dice_3: 3.167  loss_ce_4: 3.163  loss_mask_4: 1.785  loss_dice_4: 3.315  loss_ce_5: 3.128  loss_mask_5: 1.619  loss_dice_5: 3.081  loss_ce_6: 3.128  loss_mask_6: 1.529  loss_dice_6: 2.994  loss_ce_7: 2.949  loss_mask_7: 1.681  loss_dice_7: 3.007  loss_ce_8: 2.939  loss_mask_8: 1.657  loss_dice_8: 2.91  time: 1.1248  data_time: 0.0699  lr: 4.882e-05  max_mem: 20965M
[32m[04/01 17:26:25 d2.utils.events]: [0m eta: 4:37:30  iter: 439  total_loss: 80.25  loss_ce: 3.175  loss_mask: 1.543  loss_dice: 2.982  loss_ce_0: 4.23  loss_mask_0: 1.309  loss_dice_0: 2.803  loss_ce_1: 3.018  loss_mask_1: 1.399  loss_dice_1: 2.699  loss_ce_2: 3.065  loss_mask_2: 1.512  loss_dice_2: 2.952  loss_ce_3: 3.349  loss_mask_3: 1.552  loss_dice_3: 3.277  loss_ce_4: 3.376  loss_mask_4: 1.598  loss_dice_4: 3.278  loss_ce_5: 3.241  loss_mask_5: 1.588  loss_dice_5: 3.077  loss_ce_6: 3.428  loss_mask_6: 1.887  loss_dice_6: 3.666  loss_ce_7: 3.192  loss_mask_7: 1.679  loss_dice_7: 3.286  loss_ce_8: 3.179  loss_mask_8: 1.634  loss_dice_8: 3.191  time: 1.1218  data_time: 0.0622  lr: 4.8764e-05  max_mem: 20965M
[32m[04/01 17:26:46 d2.utils.events]: [0m eta: 4:36:53  iter: 459  total_loss: 77.25  loss_ce: 2.992  loss_mask: 1.613  loss_dice: 3.165  loss_ce_0: 4.058  loss_mask_0: 1.288  loss_dice_0: 2.779  loss_ce_1: 2.962  loss_mask_1: 1.355  loss_dice_1: 2.687  loss_ce_2: 3.099  loss_mask_2: 1.387  loss_dice_2: 2.901  loss_ce_3: 3.241  loss_mask_3: 1.467  loss_dice_3: 3.078  loss_ce_4: 3.19  loss_mask_4: 1.482  loss_dice_4: 3.072  loss_ce_5: 3.167  loss_mask_5: 1.477  loss_dice_5: 2.98  loss_ce_6: 3.222  loss_mask_6: 1.575  loss_dice_6: 3.456  loss_ce_7: 3.224  loss_mask_7: 1.473  loss_dice_7: 3.115  loss_ce_8: 3.018  loss_mask_8: 1.539  loss_dice_8: 3.044  time: 1.1192  data_time: 0.0649  lr: 4.8707e-05  max_mem: 20965M
[32m[04/01 17:27:08 d2.utils.events]: [0m eta: 4:36:42  iter: 479  total_loss: 75.18  loss_ce: 2.85  loss_mask: 1.533  loss_dice: 2.816  loss_ce_0: 3.96  loss_mask_0: 1.369  loss_dice_0: 2.645  loss_ce_1: 2.715  loss_mask_1: 1.496  loss_dice_1: 2.64  loss_ce_2: 2.981  loss_mask_2: 1.603  loss_dice_2: 2.895  loss_ce_3: 3.157  loss_mask_3: 1.692  loss_dice_3: 3.047  loss_ce_4: 3.121  loss_mask_4: 1.564  loss_dice_4: 3.048  loss_ce_5: 2.996  loss_mask_5: 1.641  loss_dice_5: 2.847  loss_ce_6: 2.965  loss_mask_6: 1.671  loss_dice_6: 3.285  loss_ce_7: 2.992  loss_mask_7: 1.547  loss_dice_7: 2.791  loss_ce_8: 2.913  loss_mask_8: 1.521  loss_dice_8: 2.827  time: 1.1174  data_time: 0.0614  lr: 4.8651e-05  max_mem: 20965M
[32m[04/01 17:27:29 d2.utils.events]: [0m eta: 4:36:25  iter: 499  total_loss: 78.35  loss_ce: 2.841  loss_mask: 1.524  loss_dice: 2.943  loss_ce_0: 3.849  loss_mask_0: 1.34  loss_dice_0: 2.75  loss_ce_1: 2.884  loss_mask_1: 1.517  loss_dice_1: 2.785  loss_ce_2: 3.164  loss_mask_2: 1.552  loss_dice_2: 3.047  loss_ce_3: 3.025  loss_mask_3: 1.842  loss_dice_3: 3.369  loss_ce_4: 3.313  loss_mask_4: 1.657  loss_dice_4: 3.298  loss_ce_5: 3.315  loss_mask_5: 1.693  loss_dice_5: 3.205  loss_ce_6: 3.295  loss_mask_6: 1.698  loss_dice_6: 3.191  loss_ce_7: 3.157  loss_mask_7: 1.607  loss_dice_7: 2.949  loss_ce_8: 3.059  loss_mask_8: 1.549  loss_dice_8: 2.977  time: 1.1155  data_time: 0.0564  lr: 4.8594e-05  max_mem: 20965M
[32m[04/01 17:27:51 d2.utils.events]: [0m eta: 4:36:03  iter: 519  total_loss: 76.31  loss_ce: 2.822  loss_mask: 1.44  loss_dice: 2.834  loss_ce_0: 3.726  loss_mask_0: 1.203  loss_dice_0: 2.592  loss_ce_1: 2.792  loss_mask_1: 1.366  loss_dice_1: 2.663  loss_ce_2: 3.033  loss_mask_2: 1.332  loss_dice_2: 2.783  loss_ce_3: 3.018  loss_mask_3: 1.611  loss_dice_3: 3.135  loss_ce_4: 3.126  loss_mask_4: 1.706  loss_dice_4: 3.063  loss_ce_5: 3.142  loss_mask_5: 1.891  loss_dice_5: 3.291  loss_ce_6: 3.197  loss_mask_6: 1.741  loss_dice_6: 3.33  loss_ce_7: 3.312  loss_mask_7: 1.528  loss_dice_7: 2.982  loss_ce_8: 3.169  loss_mask_8: 1.548  loss_dice_8: 2.945  time: 1.1137  data_time: 0.0669  lr: 4.8538e-05  max_mem: 20965M
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 8891349.0 ON r34n1 CANCELLED AT 2022-04-01T17:27:53 DUE TO TIME LIMIT ***
slurmstepd: error: *** JOB 8891349 ON r34n1 CANCELLED AT 2022-04-01T17:27:53 DUE TO TIME LIMIT ***
