Command Line Args: Namespace(config_file='configs/replica/semantic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_160k_res640.yaml', dist_url='tcp://127.0.0.1:55927', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '16', 'SOLVER.BASE_LR', '0.0005', 'SOLVER.MAX_ITER', '1000', 'OUTPUT_DIR', './output/swin_large/train_net_ignore_1', 'MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/maskformer/mask2former/ade20k/semantic/maskformer2_swin_large_IN21k_384_bs16_160k_res640/model_final_6b4a3a.pkl'], resume=False)
Loading config configs/replica/semantic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_160k_res640.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config configs/replica/semantic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_160k_res640.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config configs/replica/semantic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_160k_res640.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config configs/replica/semantic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_160k_res640.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config configs/replica/semantic-segmentation/swin/../Base-ADE20K-SemanticSegmentation.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config configs/replica/semantic-segmentation/swin/../Base-ADE20K-SemanticSegmentation.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config configs/replica/semantic-segmentation/swin/../Base-ADE20K-SemanticSegmentation.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config configs/replica/semantic-segmentation/swin/../Base-ADE20K-SemanticSegmentation.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
[32m[04/07 01:26:37 detectron2]: [0mRank of current process: 0. World size: 4
[32m[04/07 01:26:40 detectron2]: [0mEnvironment info:
----------------------  --------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.22.3
detectron2              0.6 @/home/fsun/mask2former/detectron2/detectron2
Compiler                GCC 8.3
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/fsun/.conda/envs/m2f/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA TITAN RTX (arch=7.5)
Driver version          470.103.01
CUDA_HOME               /sw/arch/Debian10/EB_production/2021/software/CUDA/11.3.1
Pillow                  9.0.1
torchvision             0.10.0 @/home/fsun/.conda/envs/m2f/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220305
iopath                  0.1.9
cv2                     4.5.5
----------------------  --------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2022.0-Product Build 20211112 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[32m[04/07 01:26:40 detectron2]: [0mCommand line arguments: Namespace(config_file='configs/replica/semantic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_160k_res640.yaml', dist_url='tcp://127.0.0.1:55927', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '16', 'SOLVER.BASE_LR', '0.0005', 'SOLVER.MAX_ITER', '1000', 'OUTPUT_DIR', './output/swin_large/train_net_ignore_1', 'MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/maskformer/mask2former/ade20k/semantic/maskformer2_swin_large_IN21k_384_bs16_160k_res640/model_final_6b4a3a.pkl'], resume=False)
[32m[04/07 01:26:40 detectron2]: [0mContents of args.config_file=configs/replica/semantic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_160k_res640.yaml:
_BASE_: ../maskformer2_R50_bs16_160k.yaml
MODEL:
  BACKBONE:
    NAME: "D2SwinTransformer"
  SWIN:
    EMBED_DIM: 192
    DEPTHS: [2, 2, 18, 2]
    NUM_HEADS: [6, 12, 24, 48]
    WINDOW_SIZE: 12
    APE: False
    DROP_PATH_RATE: 0.3
    PATCH_NORM: True
    PRETRAIN_IMG_SIZE: 384
  WEIGHTS: "swin_large_patch4_window12_384_22k.pkl"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
INPUT:
  MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 640) for x in range(5, 21)]"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 512 # 640
  MAX_SIZE_TRAIN: 2048 # 2560
  MAX_SIZE_TEST: 2048 # 2560
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (512, 512) # (640, 640)
    SINGLE_CATEGORY_MAX_AREA: 1.0
  COLOR_AUG_SSD: True
  SIZE_DIVISIBILITY: 512 # 640  # used in dataset mapper
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False
    MIN_SIZES: [256, 384, 512, 640, 768, 896] # [320, 480, 640, 800, 960, 1120]
    MAX_SIZE: 3584 # 4480
    FLIP: True

[32m[04/07 01:26:40 detectron2]: [0mRunning with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - replica_sem_seg_val
  TRAIN:
  - replica_sem_seg_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 512
    - 512
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 2048
  MAX_SIZE_TRAIN: 2048
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 512
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  - 1024
  - 1088
  - 1152
  - 1216
  - 1280
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 512
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: D2SwinTransformer
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    CLASS_WEIGHT: 2.0
    DEC_LAYERS: 10
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 100
    OVERSAMPLE_RATIO: 3.0
    PRE_NORM: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: false
      OBJECT_MASK_THRESHOLD: 0.8
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      SEMANTIC_ON: true
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder
    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder
  MASK_ON: false
  META_ARCHITECTURE: MaskFormer
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 1
    - 1
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: basic
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    IGNORE_VALUE: 6
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskFormerHead
    NORM: GN
    NUM_CLASSES: 30
    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    TRANSFORMER_ENC_LAYERS: 6
    USE_DEPTHWISE_SEPARABLE_CONV: false
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 192
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 6
    - 12
    - 24
    - 48
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 384
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 12
  WEIGHTS: https://dl.fbaipublicfiles.com/maskformer/mask2former/ade20k/semantic/maskformer2_swin_large_IN21k_384_bs16_160k_res640/model_final_6b4a3a.pkl
OUTPUT_DIR: ./output/swin_large/train_net_ignore_1
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0005
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 1000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 3584
    MIN_SIZES:
    - 256
    - 384
    - 512
    - 640
    - 768
    - 896
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[32m[04/07 01:26:40 detectron2]: [0mFull config saved to ./output/swin_large/train_net_ignore_1/config.yaml
[32m[04/07 01:26:40 d2.utils.env]: [0mUsing a generated random seed 40347299
[32m[04/07 01:26:49 d2.engine.defaults]: [0mModel:
MaskFormer(
  (backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (6): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (7): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (8): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (9): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (10): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (11): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (12): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (13): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (14): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (15): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (16): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (17): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=3072, out_features=1536, bias=False)
          (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=1536, out_features=4608, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1536, out_features=1536, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1536, out_features=6144, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=6144, out_features=1536, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=1536, out_features=4608, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1536, out_features=1536, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1536, out_features=6144, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=6144, out_features=1536, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=31, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 30
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
[32m[04/07 01:26:49 mask2former.data.dataset_mappers.mask_former_semantic_dataset_mapper]: [0m[MaskFormerSemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=2048, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[512, 512], single_category_max_area=1.0, ignored_category=6), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x153f021dfd90>, RandomFlip()]
train_list /home/fsun/segfusion/lists/replica/lisa_train_small.txt
[32m[04/07 01:26:49 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/07 01:26:49 d2.data.common]: [0mSerializing 1546 elements to byte tensors and concatenating them all ...
[32m[04/07 01:26:49 d2.data.common]: [0mSerialized dataset takes 0.35 MiB
[32m[04/07 01:26:52 fvcore.common.checkpoint]: [0m[Checkpointer] Loading from https://dl.fbaipublicfiles.com/maskformer/mask2former/ade20k/semantic/maskformer2_swin_large_IN21k_384_bs16_160k_res640/model_final_6b4a3a.pkl ...
[32m[04/07 01:26:54 fvcore.common.checkpoint]: [0mReading a file from 'MaskFormer Model Zoo'
[5m[31mWARNING[0m [32m[04/07 01:26:54 mask2former.modeling.transformer_decoder.mask2former_transformer_decoder]: [0mWeight format of MultiScaleMaskedTransformerDecoder have changed! Please upgrade your models. Applying automatic conversion now ...
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
train_list /home/fsun/segfusion/lists/replica/lisa_train_small.txt
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
train_list /home/fsun/segfusion/lists/replica/lisa_train_small.txt
[5m[31mWARNING[0m [32m[04/07 01:26:54 fvcore.common.checkpoint]: [0mSkip loading parameter 'sem_seg_head.predictor.class_embed.weight' to the model due to incompatible shapes: (151, 256) in the checkpoint but (31, 256) in the model! You might want to double check if this is expected.
[5m[31mWARNING[0m [32m[04/07 01:26:54 fvcore.common.checkpoint]: [0mSkip loading parameter 'sem_seg_head.predictor.class_embed.bias' to the model due to incompatible shapes: (151,) in the checkpoint but (31,) in the model! You might want to double check if this is expected.
[5m[31mWARNING[0m [32m[04/07 01:26:54 fvcore.common.checkpoint]: [0mSkip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (151,) in the checkpoint but (31,) in the model! You might want to double check if this is expected.
[5m[31mWARNING[0m [32m[04/07 01:26:54 fvcore.common.checkpoint]: [0mSome model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[32m[04/07 01:26:54 d2.engine.train_loop]: [0mStarting training from iteration 0
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
relative_position_bias_table
train_list /home/fsun/segfusion/lists/replica/lisa_train_small.txt
[32m[04/07 01:27:42 d2.utils.events]: [0m eta: 0:26:22  iter: 19  total_loss: 53.01  loss_ce: 2.815  loss_mask: 0.7615  loss_dice: 0.9946  loss_ce_0: 7.096  loss_mask_0: 0.8652  loss_dice_0: 1.281  loss_ce_1: 3.372  loss_mask_1: 0.7482  loss_dice_1: 1.064  loss_ce_2: 3.125  loss_mask_2: 0.7236  loss_dice_2: 1.056  loss_ce_3: 2.968  loss_mask_3: 0.7404  loss_dice_3: 1.009  loss_ce_4: 2.825  loss_mask_4: 0.7072  loss_dice_4: 1.066  loss_ce_5: 2.822  loss_mask_5: 0.7177  loss_dice_5: 1.041  loss_ce_6: 2.803  loss_mask_6: 0.6989  loss_dice_6: 1.014  loss_ce_7: 2.854  loss_mask_7: 0.6933  loss_dice_7: 1.014  loss_ce_8: 2.838  loss_mask_8: 0.7197  loss_dice_8: 0.9988  time: 1.7761  data_time: 0.3948  lr: 4.9144e-05  max_mem: 18181M
[32m[04/07 01:28:09 d2.utils.events]: [0m eta: 0:22:35  iter: 39  total_loss: 32.41  loss_ce: 1.059  loss_mask: 0.5497  loss_dice: 1.007  loss_ce_0: 6.176  loss_mask_0: 0.5392  loss_dice_0: 1.08  loss_ce_1: 1.502  loss_mask_1: 0.5504  loss_dice_1: 1.015  loss_ce_2: 1.295  loss_mask_2: 0.5612  loss_dice_2: 1.002  loss_ce_3: 1.224  loss_mask_3: 0.5612  loss_dice_3: 0.9751  loss_ce_4: 1.151  loss_mask_4: 0.564  loss_dice_4: 1.019  loss_ce_5: 1.093  loss_mask_5: 0.5717  loss_dice_5: 1.025  loss_ce_6: 1.091  loss_mask_6: 0.5656  loss_dice_6: 0.993  loss_ce_7: 1.082  loss_mask_7: 0.5557  loss_dice_7: 0.9872  loss_ce_8: 1.052  loss_mask_8: 0.5595  loss_dice_8: 1.033  time: 1.5454  data_time: 0.0381  lr: 4.8242e-05  max_mem: 18204M
[32m[04/07 01:28:33 d2.utils.events]: [0m eta: 0:21:42  iter: 59  total_loss: 27.49  loss_ce: 0.8071  loss_mask: 0.5047  loss_dice: 0.8656  loss_ce_0: 5.278  loss_mask_0: 0.5069  loss_dice_0: 0.8853  loss_ce_1: 1.104  loss_mask_1: 0.5165  loss_dice_1: 0.8842  loss_ce_2: 0.9832  loss_mask_2: 0.4988  loss_dice_2: 0.8563  loss_ce_3: 0.8682  loss_mask_3: 0.5018  loss_dice_3: 0.8425  loss_ce_4: 0.8498  loss_mask_4: 0.4967  loss_dice_4: 0.8735  loss_ce_5: 0.8166  loss_mask_5: 0.5085  loss_dice_5: 0.8639  loss_ce_6: 0.88  loss_mask_6: 0.5153  loss_dice_6: 0.8347  loss_ce_7: 0.7885  loss_mask_7: 0.5156  loss_dice_7: 0.8704  loss_ce_8: 0.8071  loss_mask_8: 0.5204  loss_dice_8: 0.8695  time: 1.4257  data_time: 0.0417  lr: 4.7337e-05  max_mem: 18204M
[32m[04/07 01:28:54 d2.utils.events]: [0m eta: 0:20:46  iter: 79  total_loss: 22.19  loss_ce: 0.5917  loss_mask: 0.4483  loss_dice: 0.735  loss_ce_0: 4.122  loss_mask_0: 0.4364  loss_dice_0: 0.755  loss_ce_1: 0.7851  loss_mask_1: 0.4321  loss_dice_1: 0.7184  loss_ce_2: 0.6887  loss_mask_2: 0.4458  loss_dice_2: 0.7175  loss_ce_3: 0.6327  loss_mask_3: 0.491  loss_dice_3: 0.7257  loss_ce_4: 0.6112  loss_mask_4: 0.4525  loss_dice_4: 0.7204  loss_ce_5: 0.5511  loss_mask_5: 0.4671  loss_dice_5: 0.7436  loss_ce_6: 0.5891  loss_mask_6: 0.4598  loss_dice_6: 0.7308  loss_ce_7: 0.5763  loss_mask_7: 0.4608  loss_dice_7: 0.7351  loss_ce_8: 0.5901  loss_mask_8: 0.454  loss_dice_8: 0.755  time: 1.3272  data_time: 0.0341  lr: 4.6431e-05  max_mem: 18213M
[32m[04/07 01:29:15 d2.utils.events]: [0m eta: 0:16:16  iter: 99  total_loss: 18.2  loss_ce: 0.4372  loss_mask: 0.388  loss_dice: 0.7107  loss_ce_0: 3.244  loss_mask_0: 0.393  loss_dice_0: 0.7561  loss_ce_1: 0.6509  loss_mask_1: 0.4266  loss_dice_1: 0.7322  loss_ce_2: 0.567  loss_mask_2: 0.3838  loss_dice_2: 0.7075  loss_ce_3: 0.4972  loss_mask_3: 0.3785  loss_dice_3: 0.6849  loss_ce_4: 0.4464  loss_mask_4: 0.3819  loss_dice_4: 0.7144  loss_ce_5: 0.451  loss_mask_5: 0.3758  loss_dice_5: 0.7249  loss_ce_6: 0.4288  loss_mask_6: 0.3883  loss_dice_6: 0.7294  loss_ce_7: 0.429  loss_mask_7: 0.3795  loss_dice_7: 0.7007  loss_ce_8: 0.4209  loss_mask_8: 0.3851  loss_dice_8: 0.706  time: 1.2698  data_time: 0.0368  lr: 4.5522e-05  max_mem: 18213M
[32m[04/07 01:29:36 d2.utils.events]: [0m eta: 0:15:32  iter: 119  total_loss: 16.8  loss_ce: 0.3583  loss_mask: 0.4109  loss_dice: 0.6876  loss_ce_0: 2.606  loss_mask_0: 0.3707  loss_dice_0: 0.6907  loss_ce_1: 0.5201  loss_mask_1: 0.3756  loss_dice_1: 0.6947  loss_ce_2: 0.4182  loss_mask_2: 0.3732  loss_dice_2: 0.6818  loss_ce_3: 0.3735  loss_mask_3: 0.3773  loss_dice_3: 0.6741  loss_ce_4: 0.3509  loss_mask_4: 0.3754  loss_dice_4: 0.6931  loss_ce_5: 0.3395  loss_mask_5: 0.3987  loss_dice_5: 0.6899  loss_ce_6: 0.3523  loss_mask_6: 0.4012  loss_dice_6: 0.6816  loss_ce_7: 0.3421  loss_mask_7: 0.3979  loss_dice_7: 0.6794  loss_ce_8: 0.3509  loss_mask_8: 0.4077  loss_dice_8: 0.6946  time: 1.2328  data_time: 0.0674  lr: 4.4612e-05  max_mem: 18226M
[32m[04/07 01:29:57 d2.utils.events]: [0m eta: 0:15:04  iter: 139  total_loss: 16.74  loss_ce: 0.3555  loss_mask: 0.38  loss_dice: 0.7307  loss_ce_0: 2.225  loss_mask_0: 0.4063  loss_dice_0: 0.7567  loss_ce_1: 0.4522  loss_mask_1: 0.3897  loss_dice_1: 0.7475  loss_ce_2: 0.3917  loss_mask_2: 0.3776  loss_dice_2: 0.7133  loss_ce_3: 0.3881  loss_mask_3: 0.3519  loss_dice_3: 0.7051  loss_ce_4: 0.3535  loss_mask_4: 0.3769  loss_dice_4: 0.7135  loss_ce_5: 0.3508  loss_mask_5: 0.368  loss_dice_5: 0.7115  loss_ce_6: 0.3634  loss_mask_6: 0.3665  loss_dice_6: 0.7173  loss_ce_7: 0.3407  loss_mask_7: 0.3633  loss_dice_7: 0.7314  loss_ce_8: 0.3369  loss_mask_8: 0.3639  loss_dice_8: 0.7262  time: 1.2029  data_time: 0.0501  lr: 4.3699e-05  max_mem: 18226M
[32m[04/07 01:30:18 d2.utils.events]: [0m eta: 0:14:35  iter: 159  total_loss: 16.81  loss_ce: 0.2962  loss_mask: 0.4145  loss_dice: 0.7687  loss_ce_0: 1.888  loss_mask_0: 0.4141  loss_dice_0: 0.8032  loss_ce_1: 0.4299  loss_mask_1: 0.4095  loss_dice_1: 0.7463  loss_ce_2: 0.3663  loss_mask_2: 0.4245  loss_dice_2: 0.7556  loss_ce_3: 0.3682  loss_mask_3: 0.4103  loss_dice_3: 0.7494  loss_ce_4: 0.3592  loss_mask_4: 0.4124  loss_dice_4: 0.7401  loss_ce_5: 0.3577  loss_mask_5: 0.4045  loss_dice_5: 0.7459  loss_ce_6: 0.3275  loss_mask_6: 0.415  loss_dice_6: 0.7284  loss_ce_7: 0.3088  loss_mask_7: 0.4084  loss_dice_7: 0.7515  loss_ce_8: 0.3215  loss_mask_8: 0.4087  loss_dice_8: 0.7707  time: 1.1812  data_time: 0.0514  lr: 4.2784e-05  max_mem: 18226M
[32m[04/07 01:30:38 d2.utils.events]: [0m eta: 0:14:15  iter: 179  total_loss: 16.41  loss_ce: 0.3372  loss_mask: 0.4072  loss_dice: 0.7124  loss_ce_0: 1.56  loss_mask_0: 0.3777  loss_dice_0: 0.725  loss_ce_1: 0.4441  loss_mask_1: 0.3729  loss_dice_1: 0.7116  loss_ce_2: 0.4048  loss_mask_2: 0.3846  loss_dice_2: 0.6915  loss_ce_3: 0.3782  loss_mask_3: 0.3765  loss_dice_3: 0.7094  loss_ce_4: 0.3684  loss_mask_4: 0.3606  loss_dice_4: 0.7301  loss_ce_5: 0.3619  loss_mask_5: 0.4077  loss_dice_5: 0.7202  loss_ce_6: 0.3459  loss_mask_6: 0.3937  loss_dice_6: 0.7164  loss_ce_7: 0.3457  loss_mask_7: 0.3893  loss_dice_7: 0.7193  loss_ce_8: 0.3377  loss_mask_8: 0.3822  loss_dice_8: 0.7112  time: 1.1648  data_time: 0.0670  lr: 4.1868e-05  max_mem: 18242M
[32m[04/07 01:30:59 d2.utils.events]: [0m eta: 0:13:52  iter: 199  total_loss: 14.28  loss_ce: 0.2946  loss_mask: 0.3166  loss_dice: 0.6704  loss_ce_0: 1.367  loss_mask_0: 0.3434  loss_dice_0: 0.6682  loss_ce_1: 0.4234  loss_mask_1: 0.3237  loss_dice_1: 0.6657  loss_ce_2: 0.3636  loss_mask_2: 0.3231  loss_dice_2: 0.6502  loss_ce_3: 0.3427  loss_mask_3: 0.3241  loss_dice_3: 0.6358  loss_ce_4: 0.3166  loss_mask_4: 0.3348  loss_dice_4: 0.6111  loss_ce_5: 0.3029  loss_mask_5: 0.3322  loss_dice_5: 0.6413  loss_ce_6: 0.2869  loss_mask_6: 0.3218  loss_dice_6: 0.6509  loss_ce_7: 0.2969  loss_mask_7: 0.3288  loss_dice_7: 0.6656  loss_ce_8: 0.3051  loss_mask_8: 0.3472  loss_dice_8: 0.6556  time: 1.1509  data_time: 0.0639  lr: 4.0949e-05  max_mem: 18242M
[32m[04/07 01:31:20 d2.utils.events]: [0m eta: 0:13:31  iter: 219  total_loss: 13.51  loss_ce: 0.2161  loss_mask: 0.3585  loss_dice: 0.644  loss_ce_0: 1.172  loss_mask_0: 0.3711  loss_dice_0: 0.6596  loss_ce_1: 0.3401  loss_mask_1: 0.3589  loss_dice_1: 0.6745  loss_ce_2: 0.2535  loss_mask_2: 0.3547  loss_dice_2: 0.647  loss_ce_3: 0.2535  loss_mask_3: 0.3437  loss_dice_3: 0.6239  loss_ce_4: 0.2235  loss_mask_4: 0.347  loss_dice_4: 0.6347  loss_ce_5: 0.2157  loss_mask_5: 0.3515  loss_dice_5: 0.649  loss_ce_6: 0.2156  loss_mask_6: 0.368  loss_dice_6: 0.6433  loss_ce_7: 0.2349  loss_mask_7: 0.3638  loss_dice_7: 0.6511  loss_ce_8: 0.2002  loss_mask_8: 0.3558  loss_dice_8: 0.6606  time: 1.1404  data_time: 0.0546  lr: 4.0027e-05  max_mem: 18242M
[32m[04/07 01:31:41 d2.utils.events]: [0m eta: 0:13:09  iter: 239  total_loss: 11.8  loss_ce: 0.1869  loss_mask: 0.3109  loss_dice: 0.5867  loss_ce_0: 1.113  loss_mask_0: 0.3203  loss_dice_0: 0.6122  loss_ce_1: 0.2886  loss_mask_1: 0.304  loss_dice_1: 0.6004  loss_ce_2: 0.2597  loss_mask_2: 0.3186  loss_dice_2: 0.603  loss_ce_3: 0.2262  loss_mask_3: 0.3117  loss_dice_3: 0.5859  loss_ce_4: 0.2138  loss_mask_4: 0.3212  loss_dice_4: 0.5792  loss_ce_5: 0.2199  loss_mask_5: 0.3092  loss_dice_5: 0.5684  loss_ce_6: 0.2017  loss_mask_6: 0.3082  loss_dice_6: 0.5765  loss_ce_7: 0.1986  loss_mask_7: 0.3159  loss_dice_7: 0.5797  loss_ce_8: 0.1868  loss_mask_8: 0.3109  loss_dice_8: 0.5994  time: 1.1310  data_time: 0.0727  lr: 3.9104e-05  max_mem: 18242M
[32m[04/07 01:32:01 d2.utils.events]: [0m eta: 0:12:48  iter: 259  total_loss: 13.21  loss_ce: 0.2734  loss_mask: 0.3217  loss_dice: 0.6001  loss_ce_0: 1.043  loss_mask_0: 0.3275  loss_dice_0: 0.625  loss_ce_1: 0.3119  loss_mask_1: 0.3135  loss_dice_1: 0.5972  loss_ce_2: 0.3124  loss_mask_2: 0.3113  loss_dice_2: 0.6133  loss_ce_3: 0.2973  loss_mask_3: 0.3085  loss_dice_3: 0.5789  loss_ce_4: 0.2771  loss_mask_4: 0.3045  loss_dice_4: 0.5912  loss_ce_5: 0.2742  loss_mask_5: 0.3156  loss_dice_5: 0.6215  loss_ce_6: 0.2683  loss_mask_6: 0.302  loss_dice_6: 0.6035  loss_ce_7: 0.2644  loss_mask_7: 0.3209  loss_dice_7: 0.6242  loss_ce_8: 0.2693  loss_mask_8: 0.3241  loss_dice_8: 0.6167  time: 1.1230  data_time: 0.0505  lr: 3.8177e-05  max_mem: 18242M
[32m[04/07 01:32:22 d2.utils.events]: [0m eta: 0:12:27  iter: 279  total_loss: 13.57  loss_ce: 0.1846  loss_mask: 0.3828  loss_dice: 0.6412  loss_ce_0: 0.9673  loss_mask_0: 0.3869  loss_dice_0: 0.681  loss_ce_1: 0.2617  loss_mask_1: 0.3681  loss_dice_1: 0.6286  loss_ce_2: 0.2349  loss_mask_2: 0.3707  loss_dice_2: 0.6244  loss_ce_3: 0.2181  loss_mask_3: 0.3624  loss_dice_3: 0.6163  loss_ce_4: 0.1908  loss_mask_4: 0.3607  loss_dice_4: 0.6137  loss_ce_5: 0.2094  loss_mask_5: 0.3819  loss_dice_5: 0.6291  loss_ce_6: 0.1921  loss_mask_6: 0.3805  loss_dice_6: 0.6067  loss_ce_7: 0.1846  loss_mask_7: 0.3933  loss_dice_7: 0.6323  loss_ce_8: 0.1945  loss_mask_8: 0.3862  loss_dice_8: 0.6235  time: 1.1164  data_time: 0.0623  lr: 3.7249e-05  max_mem: 18242M
[32m[04/07 01:32:43 d2.utils.events]: [0m eta: 0:12:05  iter: 299  total_loss: 13.38  loss_ce: 0.2203  loss_mask: 0.37  loss_dice: 0.6504  loss_ce_0: 0.9422  loss_mask_0: 0.3665  loss_dice_0: 0.6953  loss_ce_1: 0.2969  loss_mask_1: 0.3675  loss_dice_1: 0.6536  loss_ce_2: 0.2439  loss_mask_2: 0.3576  loss_dice_2: 0.6499  loss_ce_3: 0.2228  loss_mask_3: 0.3564  loss_dice_3: 0.6559  loss_ce_4: 0.2108  loss_mask_4: 0.369  loss_dice_4: 0.6471  loss_ce_5: 0.2059  loss_mask_5: 0.3577  loss_dice_5: 0.6552  loss_ce_6: 0.182  loss_mask_6: 0.3595  loss_dice_6: 0.6655  loss_ce_7: 0.2126  loss_mask_7: 0.3644  loss_dice_7: 0.6566  loss_ce_8: 0.2263  loss_mask_8: 0.3623  loss_dice_8: 0.6608  time: 1.1107  data_time: 0.0609  lr: 3.6318e-05  max_mem: 18242M
[32m[04/07 01:33:03 d2.utils.events]: [0m eta: 0:11:44  iter: 319  total_loss: 10.8  loss_ce: 0.1576  loss_mask: 0.2618  loss_dice: 0.5462  loss_ce_0: 0.8273  loss_mask_0: 0.2902  loss_dice_0: 0.5624  loss_ce_1: 0.2624  loss_mask_1: 0.2736  loss_dice_1: 0.5608  loss_ce_2: 0.1968  loss_mask_2: 0.2625  loss_dice_2: 0.5486  loss_ce_3: 0.1684  loss_mask_3: 0.2779  loss_dice_3: 0.5338  loss_ce_4: 0.1852  loss_mask_4: 0.2757  loss_dice_4: 0.5354  loss_ce_5: 0.2076  loss_mask_5: 0.2705  loss_dice_5: 0.5417  loss_ce_6: 0.1717  loss_mask_6: 0.2787  loss_dice_6: 0.5465  loss_ce_7: 0.1761  loss_mask_7: 0.2763  loss_dice_7: 0.5522  loss_ce_8: 0.1558  loss_mask_8: 0.2666  loss_dice_8: 0.5438  time: 1.1051  data_time: 0.0605  lr: 3.5384e-05  max_mem: 18242M
[32m[04/07 01:33:24 d2.utils.events]: [0m eta: 0:11:22  iter: 339  total_loss: 11.24  loss_ce: 0.1618  loss_mask: 0.307  loss_dice: 0.5927  loss_ce_0: 0.8382  loss_mask_0: 0.3191  loss_dice_0: 0.6165  loss_ce_1: 0.2513  loss_mask_1: 0.305  loss_dice_1: 0.5962  loss_ce_2: 0.1999  loss_mask_2: 0.2946  loss_dice_2: 0.5898  loss_ce_3: 0.1973  loss_mask_3: 0.2879  loss_dice_3: 0.5518  loss_ce_4: 0.1884  loss_mask_4: 0.288  loss_dice_4: 0.5812  loss_ce_5: 0.179  loss_mask_5: 0.2939  loss_dice_5: 0.5858  loss_ce_6: 0.1647  loss_mask_6: 0.2825  loss_dice_6: 0.559  loss_ce_7: 0.1659  loss_mask_7: 0.2853  loss_dice_7: 0.5837  loss_ce_8: 0.1669  loss_mask_8: 0.2972  loss_dice_8: 0.5702  time: 1.1003  data_time: 0.0644  lr: 3.4447e-05  max_mem: 18242M
[32m[04/07 01:33:45 d2.utils.events]: [0m eta: 0:11:01  iter: 359  total_loss: 11.8  loss_ce: 0.2242  loss_mask: 0.2756  loss_dice: 0.5598  loss_ce_0: 0.8418  loss_mask_0: 0.3004  loss_dice_0: 0.6125  loss_ce_1: 0.2502  loss_mask_1: 0.285  loss_dice_1: 0.5672  loss_ce_2: 0.2337  loss_mask_2: 0.2702  loss_dice_2: 0.5556  loss_ce_3: 0.2177  loss_mask_3: 0.2841  loss_dice_3: 0.5724  loss_ce_4: 0.2314  loss_mask_4: 0.2963  loss_dice_4: 0.5671  loss_ce_5: 0.2165  loss_mask_5: 0.2904  loss_dice_5: 0.568  loss_ce_6: 0.2176  loss_mask_6: 0.2803  loss_dice_6: 0.5591  loss_ce_7: 0.2067  loss_mask_7: 0.2787  loss_dice_7: 0.5752  loss_ce_8: 0.2273  loss_mask_8: 0.2849  loss_dice_8: 0.6004  time: 1.0965  data_time: 0.0597  lr: 3.3508e-05  max_mem: 18242M
[32m[04/07 01:34:06 d2.utils.events]: [0m eta: 0:10:40  iter: 379  total_loss: 11.64  loss_ce: 0.1767  loss_mask: 0.2882  loss_dice: 0.5615  loss_ce_0: 0.8378  loss_mask_0: 0.301  loss_dice_0: 0.6051  loss_ce_1: 0.2609  loss_mask_1: 0.2919  loss_dice_1: 0.5746  loss_ce_2: 0.2471  loss_mask_2: 0.281  loss_dice_2: 0.5576  loss_ce_3: 0.2196  loss_mask_3: 0.2802  loss_dice_3: 0.5716  loss_ce_4: 0.1974  loss_mask_4: 0.2847  loss_dice_4: 0.5715  loss_ce_5: 0.221  loss_mask_5: 0.282  loss_dice_5: 0.5826  loss_ce_6: 0.1571  loss_mask_6: 0.2915  loss_dice_6: 0.5696  loss_ce_7: 0.1714  loss_mask_7: 0.2893  loss_dice_7: 0.5492  loss_ce_8: 0.193  loss_mask_8: 0.2879  loss_dice_8: 0.5652  time: 1.0931  data_time: 0.0580  lr: 3.2565e-05  max_mem: 18242M
[32m[04/07 01:34:26 d2.utils.events]: [0m eta: 0:10:19  iter: 399  total_loss: 11.18  loss_ce: 0.1541  loss_mask: 0.3068  loss_dice: 0.5595  loss_ce_0: 0.7919  loss_mask_0: 0.3242  loss_dice_0: 0.614  loss_ce_1: 0.2433  loss_mask_1: 0.3046  loss_dice_1: 0.5988  loss_ce_2: 0.2079  loss_mask_2: 0.3136  loss_dice_2: 0.591  loss_ce_3: 0.1885  loss_mask_3: 0.3055  loss_dice_3: 0.5677  loss_ce_4: 0.183  loss_mask_4: 0.3021  loss_dice_4: 0.5715  loss_ce_5: 0.1864  loss_mask_5: 0.3089  loss_dice_5: 0.5868  loss_ce_6: 0.173  loss_mask_6: 0.3003  loss_dice_6: 0.585  loss_ce_7: 0.152  loss_mask_7: 0.3086  loss_dice_7: 0.5687  loss_ce_8: 0.179  loss_mask_8: 0.3181  loss_dice_8: 0.5748  time: 1.0899  data_time: 0.0661  lr: 3.162e-05  max_mem: 18242M
[32m[04/07 01:34:47 d2.utils.events]: [0m eta: 0:09:59  iter: 419  total_loss: 10.92  loss_ce: 0.1552  loss_mask: 0.2791  loss_dice: 0.5803  loss_ce_0: 0.756  loss_mask_0: 0.2842  loss_dice_0: 0.601  loss_ce_1: 0.2225  loss_mask_1: 0.2844  loss_dice_1: 0.5761  loss_ce_2: 0.1957  loss_mask_2: 0.2951  loss_dice_2: 0.5766  loss_ce_3: 0.1834  loss_mask_3: 0.2901  loss_dice_3: 0.5669  loss_ce_4: 0.1625  loss_mask_4: 0.2912  loss_dice_4: 0.5634  loss_ce_5: 0.1665  loss_mask_5: 0.2809  loss_dice_5: 0.5862  loss_ce_6: 0.1516  loss_mask_6: 0.2909  loss_dice_6: 0.5487  loss_ce_7: 0.1543  loss_mask_7: 0.2745  loss_dice_7: 0.5865  loss_ce_8: 0.1635  loss_mask_8: 0.2832  loss_dice_8: 0.5888  time: 1.0877  data_time: 0.0512  lr: 3.0671e-05  max_mem: 18242M
[32m[04/07 01:35:08 d2.utils.events]: [0m eta: 0:09:39  iter: 439  total_loss: 10.76  loss_ce: 0.1643  loss_mask: 0.292  loss_dice: 0.5711  loss_ce_0: 0.749  loss_mask_0: 0.3116  loss_dice_0: 0.61  loss_ce_1: 0.2239  loss_mask_1: 0.285  loss_dice_1: 0.5709  loss_ce_2: 0.1657  loss_mask_2: 0.2714  loss_dice_2: 0.5762  loss_ce_3: 0.1439  loss_mask_3: 0.2709  loss_dice_3: 0.5598  loss_ce_4: 0.1625  loss_mask_4: 0.2822  loss_dice_4: 0.5473  loss_ce_5: 0.159  loss_mask_5: 0.2824  loss_dice_5: 0.5484  loss_ce_6: 0.1634  loss_mask_6: 0.2853  loss_dice_6: 0.5404  loss_ce_7: 0.1755  loss_mask_7: 0.2931  loss_dice_7: 0.553  loss_ce_8: 0.1806  loss_mask_8: 0.2767  loss_dice_8: 0.5578  time: 1.0856  data_time: 0.0661  lr: 2.9719e-05  max_mem: 18242M
[32m[04/07 01:35:29 d2.utils.events]: [0m eta: 0:09:18  iter: 459  total_loss: 10.25  loss_ce: 0.1737  loss_mask: 0.2601  loss_dice: 0.5333  loss_ce_0: 0.7608  loss_mask_0: 0.2584  loss_dice_0: 0.5713  loss_ce_1: 0.2499  loss_mask_1: 0.2575  loss_dice_1: 0.536  loss_ce_2: 0.2009  loss_mask_2: 0.2542  loss_dice_2: 0.5482  loss_ce_3: 0.1712  loss_mask_3: 0.2507  loss_dice_3: 0.5366  loss_ce_4: 0.2004  loss_mask_4: 0.2472  loss_dice_4: 0.5646  loss_ce_5: 0.2078  loss_mask_5: 0.2527  loss_dice_5: 0.5438  loss_ce_6: 0.1998  loss_mask_6: 0.2549  loss_dice_6: 0.5331  loss_ce_7: 0.1859  loss_mask_7: 0.2511  loss_dice_7: 0.5395  loss_ce_8: 0.1753  loss_mask_8: 0.254  loss_dice_8: 0.5385  time: 1.0832  data_time: 0.0597  lr: 2.8764e-05  max_mem: 18242M
[32m[04/07 01:35:49 d2.utils.events]: [0m eta: 0:08:57  iter: 479  total_loss: 10.33  loss_ce: 0.1195  loss_mask: 0.2935  loss_dice: 0.5233  loss_ce_0: 0.7062  loss_mask_0: 0.2998  loss_dice_0: 0.5804  loss_ce_1: 0.2164  loss_mask_1: 0.3079  loss_dice_1: 0.5292  loss_ce_2: 0.1644  loss_mask_2: 0.305  loss_dice_2: 0.5537  loss_ce_3: 0.1641  loss_mask_3: 0.2991  loss_dice_3: 0.5232  loss_ce_4: 0.1433  loss_mask_4: 0.2979  loss_dice_4: 0.5287  loss_ce_5: 0.1287  loss_mask_5: 0.2943  loss_dice_5: 0.532  loss_ce_6: 0.1451  loss_mask_6: 0.2931  loss_dice_6: 0.5273  loss_ce_7: 0.1392  loss_mask_7: 0.2934  loss_dice_7: 0.5661  loss_ce_8: 0.1316  loss_mask_8: 0.2952  loss_dice_8: 0.5438  time: 1.0808  data_time: 0.0584  lr: 2.7805e-05  max_mem: 18242M
[32m[04/07 01:36:10 d2.utils.events]: [0m eta: 0:08:36  iter: 499  total_loss: 10.44  loss_ce: 0.1047  loss_mask: 0.2717  loss_dice: 0.5543  loss_ce_0: 0.6629  loss_mask_0: 0.2901  loss_dice_0: 0.5749  loss_ce_1: 0.1646  loss_mask_1: 0.2694  loss_dice_1: 0.5584  loss_ce_2: 0.1489  loss_mask_2: 0.2659  loss_dice_2: 0.5705  loss_ce_3: 0.1422  loss_mask_3: 0.2681  loss_dice_3: 0.5373  loss_ce_4: 0.1226  loss_mask_4: 0.2778  loss_dice_4: 0.5478  loss_ce_5: 0.1218  loss_mask_5: 0.2817  loss_dice_5: 0.5469  loss_ce_6: 0.1144  loss_mask_6: 0.2691  loss_dice_6: 0.5611  loss_ce_7: 0.1336  loss_mask_7: 0.2718  loss_dice_7: 0.558  loss_ce_8: 0.1077  loss_mask_8: 0.2713  loss_dice_8: 0.5641  time: 1.0785  data_time: 0.0590  lr: 2.6843e-05  max_mem: 18242M
[32m[04/07 01:36:31 d2.utils.events]: [0m eta: 0:08:15  iter: 519  total_loss: 9.366  loss_ce: 0.1345  loss_mask: 0.236  loss_dice: 0.4738  loss_ce_0: 0.6924  loss_mask_0: 0.2593  loss_dice_0: 0.5136  loss_ce_1: 0.1753  loss_mask_1: 0.2361  loss_dice_1: 0.5022  loss_ce_2: 0.1653  loss_mask_2: 0.2434  loss_dice_2: 0.4955  loss_ce_3: 0.1252  loss_mask_3: 0.241  loss_dice_3: 0.4731  loss_ce_4: 0.1283  loss_mask_4: 0.2397  loss_dice_4: 0.4689  loss_ce_5: 0.138  loss_mask_5: 0.2366  loss_dice_5: 0.4669  loss_ce_6: 0.1365  loss_mask_6: 0.238  loss_dice_6: 0.4707  loss_ce_7: 0.1385  loss_mask_7: 0.2334  loss_dice_7: 0.4693  loss_ce_8: 0.1388  loss_mask_8: 0.2359  loss_dice_8: 0.4764  time: 1.0778  data_time: 0.0553  lr: 2.5876e-05  max_mem: 18242M
[32m[04/07 01:36:52 d2.utils.events]: [0m eta: 0:07:54  iter: 539  total_loss: 10.04  loss_ce: 0.1282  loss_mask: 0.2628  loss_dice: 0.5096  loss_ce_0: 0.6951  loss_mask_0: 0.2923  loss_dice_0: 0.5474  loss_ce_1: 0.207  loss_mask_1: 0.2594  loss_dice_1: 0.5316  loss_ce_2: 0.1806  loss_mask_2: 0.2604  loss_dice_2: 0.5329  loss_ce_3: 0.1673  loss_mask_3: 0.2551  loss_dice_3: 0.5139  loss_ce_4: 0.1658  loss_mask_4: 0.2615  loss_dice_4: 0.5336  loss_ce_5: 0.1608  loss_mask_5: 0.2621  loss_dice_5: 0.526  loss_ce_6: 0.1531  loss_mask_6: 0.2577  loss_dice_6: 0.5126  loss_ce_7: 0.1399  loss_mask_7: 0.2598  loss_dice_7: 0.5098  loss_ce_8: 0.1534  loss_mask_8: 0.2636  loss_dice_8: 0.5236  time: 1.0756  data_time: 0.0556  lr: 2.4906e-05  max_mem: 18242M
[32m[04/07 01:37:12 d2.utils.events]: [0m eta: 0:07:34  iter: 559  total_loss: 9.415  loss_ce: 0.1146  loss_mask: 0.2226  loss_dice: 0.4727  loss_ce_0: 0.6565  loss_mask_0: 0.2346  loss_dice_0: 0.535  loss_ce_1: 0.1635  loss_mask_1: 0.224  loss_dice_1: 0.4841  loss_ce_2: 0.1482  loss_mask_2: 0.2191  loss_dice_2: 0.5059  loss_ce_3: 0.1244  loss_mask_3: 0.2216  loss_dice_3: 0.4958  loss_ce_4: 0.147  loss_mask_4: 0.2221  loss_dice_4: 0.4883  loss_ce_5: 0.1309  loss_mask_5: 0.2226  loss_dice_5: 0.4744  loss_ce_6: 0.1155  loss_mask_6: 0.2209  loss_dice_6: 0.4775  loss_ce_7: 0.1244  loss_mask_7: 0.2182  loss_dice_7: 0.4758  loss_ce_8: 0.1233  loss_mask_8: 0.2214  loss_dice_8: 0.4889  time: 1.0738  data_time: 0.0470  lr: 2.3931e-05  max_mem: 18242M
[32m[04/07 01:37:33 d2.utils.events]: [0m eta: 0:07:13  iter: 579  total_loss: 8.95  loss_ce: 0.1342  loss_mask: 0.2345  loss_dice: 0.449  loss_ce_0: 0.6754  loss_mask_0: 0.2524  loss_dice_0: 0.4952  loss_ce_1: 0.1944  loss_mask_1: 0.2344  loss_dice_1: 0.476  loss_ce_2: 0.1377  loss_mask_2: 0.2353  loss_dice_2: 0.4775  loss_ce_3: 0.1438  loss_mask_3: 0.233  loss_dice_3: 0.4652  loss_ce_4: 0.151  loss_mask_4: 0.2365  loss_dice_4: 0.4593  loss_ce_5: 0.1499  loss_mask_5: 0.2313  loss_dice_5: 0.4509  loss_ce_6: 0.1432  loss_mask_6: 0.2335  loss_dice_6: 0.445  loss_ce_7: 0.1529  loss_mask_7: 0.2323  loss_dice_7: 0.4553  loss_ce_8: 0.1408  loss_mask_8: 0.2356  loss_dice_8: 0.4674  time: 1.0723  data_time: 0.0493  lr: 2.2952e-05  max_mem: 18242M
[32m[04/07 01:37:54 d2.utils.events]: [0m eta: 0:06:52  iter: 599  total_loss: 9.453  loss_ce: 0.1172  loss_mask: 0.2291  loss_dice: 0.4794  loss_ce_0: 0.6232  loss_mask_0: 0.2435  loss_dice_0: 0.4854  loss_ce_1: 0.1696  loss_mask_1: 0.2227  loss_dice_1: 0.4931  loss_ce_2: 0.134  loss_mask_2: 0.2384  loss_dice_2: 0.4923  loss_ce_3: 0.1431  loss_mask_3: 0.2292  loss_dice_3: 0.4924  loss_ce_4: 0.1434  loss_mask_4: 0.229  loss_dice_4: 0.4822  loss_ce_5: 0.1244  loss_mask_5: 0.221  loss_dice_5: 0.489  loss_ce_6: 0.111  loss_mask_6: 0.2248  loss_dice_6: 0.4841  loss_ce_7: 0.1176  loss_mask_7: 0.226  loss_dice_7: 0.5012  loss_ce_8: 0.1144  loss_mask_8: 0.2284  loss_dice_8: 0.4975  time: 1.0708  data_time: 0.0612  lr: 2.1968e-05  max_mem: 18242M
[32m[04/07 01:38:14 d2.utils.events]: [0m eta: 0:06:32  iter: 619  total_loss: 8.801  loss_ce: 0.1156  loss_mask: 0.2209  loss_dice: 0.4811  loss_ce_0: 0.6629  loss_mask_0: 0.2397  loss_dice_0: 0.5096  loss_ce_1: 0.1458  loss_mask_1: 0.2217  loss_dice_1: 0.4882  loss_ce_2: 0.1473  loss_mask_2: 0.2159  loss_dice_2: 0.4802  loss_ce_3: 0.1413  loss_mask_3: 0.2221  loss_dice_3: 0.4792  loss_ce_4: 0.1095  loss_mask_4: 0.2207  loss_dice_4: 0.4699  loss_ce_5: 0.1188  loss_mask_5: 0.2223  loss_dice_5: 0.4741  loss_ce_6: 0.1068  loss_mask_6: 0.2251  loss_dice_6: 0.4704  loss_ce_7: 0.108  loss_mask_7: 0.2253  loss_dice_7: 0.4794  loss_ce_8: 0.1158  loss_mask_8: 0.2204  loss_dice_8: 0.4859  time: 1.0694  data_time: 0.0582  lr: 2.098e-05  max_mem: 18242M
[32m[04/07 01:38:35 d2.utils.events]: [0m eta: 0:06:11  iter: 639  total_loss: 8.689  loss_ce: 0.13  loss_mask: 0.2171  loss_dice: 0.4484  loss_ce_0: 0.6226  loss_mask_0: 0.2256  loss_dice_0: 0.4761  loss_ce_1: 0.134  loss_mask_1: 0.2168  loss_dice_1: 0.4724  loss_ce_2: 0.1211  loss_mask_2: 0.2165  loss_dice_2: 0.4659  loss_ce_3: 0.1184  loss_mask_3: 0.217  loss_dice_3: 0.4483  loss_ce_4: 0.1104  loss_mask_4: 0.2165  loss_dice_4: 0.4469  loss_ce_5: 0.1165  loss_mask_5: 0.2149  loss_dice_5: 0.433  loss_ce_6: 0.1285  loss_mask_6: 0.2183  loss_dice_6: 0.4467  loss_ce_7: 0.1296  loss_mask_7: 0.2164  loss_dice_7: 0.4366  loss_ce_8: 0.1236  loss_mask_8: 0.2157  loss_dice_8: 0.4601  time: 1.0680  data_time: 0.0547  lr: 1.9986e-05  max_mem: 18242M
[32m[04/07 01:38:55 d2.utils.events]: [0m eta: 0:05:50  iter: 659  total_loss: 8.521  loss_ce: 0.08176  loss_mask: 0.2107  loss_dice: 0.4612  loss_ce_0: 0.6285  loss_mask_0: 0.2214  loss_dice_0: 0.4733  loss_ce_1: 0.1058  loss_mask_1: 0.2133  loss_dice_1: 0.4879  loss_ce_2: 0.09524  loss_mask_2: 0.211  loss_dice_2: 0.4876  loss_ce_3: 0.07988  loss_mask_3: 0.2099  loss_dice_3: 0.445  loss_ce_4: 0.09311  loss_mask_4: 0.21  loss_dice_4: 0.4535  loss_ce_5: 0.08397  loss_mask_5: 0.2097  loss_dice_5: 0.4663  loss_ce_6: 0.06496  loss_mask_6: 0.2114  loss_dice_6: 0.4637  loss_ce_7: 0.07018  loss_mask_7: 0.2102  loss_dice_7: 0.4613  loss_ce_8: 0.07415  loss_mask_8: 0.2102  loss_dice_8: 0.4517  time: 1.0663  data_time: 0.0526  lr: 1.8987e-05  max_mem: 18242M
[32m[04/07 01:39:16 d2.utils.events]: [0m eta: 0:05:30  iter: 679  total_loss: 8.935  loss_ce: 0.1241  loss_mask: 0.2426  loss_dice: 0.4766  loss_ce_0: 0.673  loss_mask_0: 0.2438  loss_dice_0: 0.5202  loss_ce_1: 0.1346  loss_mask_1: 0.247  loss_dice_1: 0.4862  loss_ce_2: 0.1352  loss_mask_2: 0.2455  loss_dice_2: 0.4687  loss_ce_3: 0.09701  loss_mask_3: 0.2452  loss_dice_3: 0.4619  loss_ce_4: 0.1224  loss_mask_4: 0.2538  loss_dice_4: 0.4614  loss_ce_5: 0.1264  loss_mask_5: 0.252  loss_dice_5: 0.4778  loss_ce_6: 0.1098  loss_mask_6: 0.2472  loss_dice_6: 0.472  loss_ce_7: 0.148  loss_mask_7: 0.2472  loss_dice_7: 0.4795  loss_ce_8: 0.1319  loss_mask_8: 0.2455  loss_dice_8: 0.4818  time: 1.0654  data_time: 0.0558  lr: 1.7981e-05  max_mem: 18242M
[32m[04/07 01:39:37 d2.utils.events]: [0m eta: 0:05:09  iter: 699  total_loss: 8.957  loss_ce: 0.08777  loss_mask: 0.2394  loss_dice: 0.5  loss_ce_0: 0.5735  loss_mask_0: 0.2397  loss_dice_0: 0.5081  loss_ce_1: 0.08736  loss_mask_1: 0.2357  loss_dice_1: 0.5061  loss_ce_2: 0.1009  loss_mask_2: 0.2322  loss_dice_2: 0.4945  loss_ce_3: 0.1001  loss_mask_3: 0.2278  loss_dice_3: 0.4898  loss_ce_4: 0.09066  loss_mask_4: 0.2259  loss_dice_4: 0.5018  loss_ce_5: 0.09727  loss_mask_5: 0.2281  loss_dice_5: 0.5088  loss_ce_6: 0.1004  loss_mask_6: 0.2299  loss_dice_6: 0.4809  loss_ce_7: 0.09493  loss_mask_7: 0.2313  loss_dice_7: 0.4842  loss_ce_8: 0.09279  loss_mask_8: 0.2379  loss_dice_8: 0.4924  time: 1.0643  data_time: 0.0561  lr: 1.697e-05  max_mem: 18242M
[32m[04/07 01:39:58 d2.utils.events]: [0m eta: 0:04:48  iter: 719  total_loss: 8.818  loss_ce: 0.1016  loss_mask: 0.2241  loss_dice: 0.4693  loss_ce_0: 0.617  loss_mask_0: 0.2456  loss_dice_0: 0.5046  loss_ce_1: 0.1546  loss_mask_1: 0.2344  loss_dice_1: 0.4886  loss_ce_2: 0.1396  loss_mask_2: 0.2338  loss_dice_2: 0.4654  loss_ce_3: 0.1418  loss_mask_3: 0.2361  loss_dice_3: 0.4401  loss_ce_4: 0.127  loss_mask_4: 0.2267  loss_dice_4: 0.486  loss_ce_5: 0.1098  loss_mask_5: 0.2344  loss_dice_5: 0.4435  loss_ce_6: 0.1085  loss_mask_6: 0.2323  loss_dice_6: 0.4607  loss_ce_7: 0.1083  loss_mask_7: 0.2293  loss_dice_7: 0.4588  loss_ce_8: 0.0966  loss_mask_8: 0.2295  loss_dice_8: 0.4809  time: 1.0635  data_time: 0.0626  lr: 1.5952e-05  max_mem: 18242M
[32m[04/07 01:40:18 d2.utils.events]: [0m eta: 0:04:28  iter: 739  total_loss: 8.44  loss_ce: 0.1092  loss_mask: 0.2084  loss_dice: 0.4611  loss_ce_0: 0.6341  loss_mask_0: 0.2162  loss_dice_0: 0.4938  loss_ce_1: 0.1189  loss_mask_1: 0.2062  loss_dice_1: 0.4941  loss_ce_2: 0.1186  loss_mask_2: 0.2069  loss_dice_2: 0.4725  loss_ce_3: 0.1163  loss_mask_3: 0.2082  loss_dice_3: 0.4488  loss_ce_4: 0.1181  loss_mask_4: 0.2108  loss_dice_4: 0.464  loss_ce_5: 0.1179  loss_mask_5: 0.2069  loss_dice_5: 0.4788  loss_ce_6: 0.0955  loss_mask_6: 0.2095  loss_dice_6: 0.4474  loss_ce_7: 0.08919  loss_mask_7: 0.2062  loss_dice_7: 0.4632  loss_ce_8: 0.105  loss_mask_8: 0.2078  loss_dice_8: 0.4309  time: 1.0624  data_time: 0.0714  lr: 1.4926e-05  max_mem: 18242M
[32m[04/07 01:40:39 d2.utils.events]: [0m eta: 0:04:07  iter: 759  total_loss: 8.568  loss_ce: 0.1008  loss_mask: 0.2348  loss_dice: 0.4502  loss_ce_0: 0.6108  loss_mask_0: 0.2571  loss_dice_0: 0.4737  loss_ce_1: 0.08131  loss_mask_1: 0.2421  loss_dice_1: 0.4638  loss_ce_2: 0.09234  loss_mask_2: 0.2447  loss_dice_2: 0.4565  loss_ce_3: 0.09019  loss_mask_3: 0.2369  loss_dice_3: 0.4592  loss_ce_4: 0.09086  loss_mask_4: 0.2404  loss_dice_4: 0.4514  loss_ce_5: 0.07607  loss_mask_5: 0.2382  loss_dice_5: 0.4598  loss_ce_6: 0.08302  loss_mask_6: 0.2339  loss_dice_6: 0.4575  loss_ce_7: 0.07281  loss_mask_7: 0.2369  loss_dice_7: 0.4503  loss_ce_8: 0.09464  loss_mask_8: 0.2381  loss_dice_8: 0.4667  time: 1.0617  data_time: 0.0661  lr: 1.3893e-05  max_mem: 18242M
[32m[04/07 01:41:00 d2.utils.events]: [0m eta: 0:03:47  iter: 779  total_loss: 7.911  loss_ce: 0.09261  loss_mask: 0.213  loss_dice: 0.4096  loss_ce_0: 0.6008  loss_mask_0: 0.2193  loss_dice_0: 0.4246  loss_ce_1: 0.1035  loss_mask_1: 0.2218  loss_dice_1: 0.4146  loss_ce_2: 0.1025  loss_mask_2: 0.2108  loss_dice_2: 0.4201  loss_ce_3: 0.11  loss_mask_3: 0.2098  loss_dice_3: 0.4141  loss_ce_4: 0.1052  loss_mask_4: 0.2115  loss_dice_4: 0.4082  loss_ce_5: 0.1009  loss_mask_5: 0.2107  loss_dice_5: 0.4249  loss_ce_6: 0.1041  loss_mask_6: 0.214  loss_dice_6: 0.424  loss_ce_7: 0.09957  loss_mask_7: 0.2148  loss_dice_7: 0.4061  loss_ce_8: 0.1017  loss_mask_8: 0.2132  loss_dice_8: 0.4185  time: 1.0609  data_time: 0.0585  lr: 1.2851e-05  max_mem: 18242M
[32m[04/07 01:41:21 d2.utils.events]: [0m eta: 0:03:26  iter: 799  total_loss: 7.155  loss_ce: 0.05602  loss_mask: 0.1842  loss_dice: 0.3703  loss_ce_0: 0.5785  loss_mask_0: 0.1925  loss_dice_0: 0.4121  loss_ce_1: 0.08173  loss_mask_1: 0.1835  loss_dice_1: 0.379  loss_ce_2: 0.0636  loss_mask_2: 0.182  loss_dice_2: 0.3934  loss_ce_3: 0.09521  loss_mask_3: 0.1782  loss_dice_3: 0.3966  loss_ce_4: 0.07388  loss_mask_4: 0.1806  loss_dice_4: 0.3795  loss_ce_5: 0.08153  loss_mask_5: 0.1798  loss_dice_5: 0.3857  loss_ce_6: 0.09459  loss_mask_6: 0.1779  loss_dice_6: 0.3727  loss_ce_7: 0.08583  loss_mask_7: 0.1809  loss_dice_7: 0.3906  loss_ce_8: 0.05945  loss_mask_8: 0.1824  loss_dice_8: 0.3742  time: 1.0602  data_time: 0.0559  lr: 1.1799e-05  max_mem: 18242M
[32m[04/07 01:41:41 d2.utils.events]: [0m eta: 0:03:05  iter: 819  total_loss: 7.322  loss_ce: 0.08347  loss_mask: 0.2023  loss_dice: 0.42  loss_ce_0: 0.6049  loss_mask_0: 0.2126  loss_dice_0: 0.473  loss_ce_1: 0.1223  loss_mask_1: 0.2015  loss_dice_1: 0.4408  loss_ce_2: 0.1132  loss_mask_2: 0.2018  loss_dice_2: 0.4158  loss_ce_3: 0.09443  loss_mask_3: 0.2004  loss_dice_3: 0.4214  loss_ce_4: 0.09702  loss_mask_4: 0.2001  loss_dice_4: 0.4365  loss_ce_5: 0.09463  loss_mask_5: 0.2039  loss_dice_5: 0.4044  loss_ce_6: 0.09952  loss_mask_6: 0.2013  loss_dice_6: 0.4342  loss_ce_7: 0.0847  loss_mask_7: 0.2015  loss_dice_7: 0.401  loss_ce_8: 0.09059  loss_mask_8: 0.1993  loss_dice_8: 0.4145  time: 1.0595  data_time: 0.0499  lr: 1.0737e-05  max_mem: 18242M
[32m[04/07 01:42:02 d2.utils.events]: [0m eta: 0:02:45  iter: 839  total_loss: 7.66  loss_ce: 0.07165  loss_mask: 0.2113  loss_dice: 0.3977  loss_ce_0: 0.6001  loss_mask_0: 0.2303  loss_dice_0: 0.4194  loss_ce_1: 0.1018  loss_mask_1: 0.2183  loss_dice_1: 0.3911  loss_ce_2: 0.08666  loss_mask_2: 0.2137  loss_dice_2: 0.3982  loss_ce_3: 0.09889  loss_mask_3: 0.2058  loss_dice_3: 0.385  loss_ce_4: 0.08821  loss_mask_4: 0.2125  loss_dice_4: 0.3869  loss_ce_5: 0.07426  loss_mask_5: 0.2156  loss_dice_5: 0.3933  loss_ce_6: 0.07494  loss_mask_6: 0.2074  loss_dice_6: 0.3903  loss_ce_7: 0.0851  loss_mask_7: 0.2079  loss_dice_7: 0.3889  loss_ce_8: 0.06151  loss_mask_8: 0.2088  loss_dice_8: 0.3848  time: 1.0586  data_time: 0.0606  lr: 9.663e-06  max_mem: 18242M
[32m[04/07 01:42:23 d2.utils.events]: [0m eta: 0:02:24  iter: 859  total_loss: 7.055  loss_ce: 0.05655  loss_mask: 0.1804  loss_dice: 0.3907  loss_ce_0: 0.5377  loss_mask_0: 0.1854  loss_dice_0: 0.4092  loss_ce_1: 0.06973  loss_mask_1: 0.1816  loss_dice_1: 0.4126  loss_ce_2: 0.05465  loss_mask_2: 0.1824  loss_dice_2: 0.3964  loss_ce_3: 0.04878  loss_mask_3: 0.1812  loss_dice_3: 0.3911  loss_ce_4: 0.06898  loss_mask_4: 0.182  loss_dice_4: 0.3927  loss_ce_5: 0.07428  loss_mask_5: 0.1812  loss_dice_5: 0.403  loss_ce_6: 0.07964  loss_mask_6: 0.1836  loss_dice_6: 0.3938  loss_ce_7: 0.06141  loss_mask_7: 0.1911  loss_dice_7: 0.4073  loss_ce_8: 0.0537  loss_mask_8: 0.1815  loss_dice_8: 0.4024  time: 1.0579  data_time: 0.0596  lr: 8.5757e-06  max_mem: 18242M
[32m[04/07 01:42:43 d2.utils.events]: [0m eta: 0:02:03  iter: 879  total_loss: 7.252  loss_ce: 0.05849  loss_mask: 0.1913  loss_dice: 0.4007  loss_ce_0: 0.5853  loss_mask_0: 0.2073  loss_dice_0: 0.4227  loss_ce_1: 0.09312  loss_mask_1: 0.1909  loss_dice_1: 0.417  loss_ce_2: 0.07771  loss_mask_2: 0.1932  loss_dice_2: 0.3966  loss_ce_3: 0.08978  loss_mask_3: 0.1898  loss_dice_3: 0.4001  loss_ce_4: 0.07226  loss_mask_4: 0.1931  loss_dice_4: 0.3829  loss_ce_5: 0.06856  loss_mask_5: 0.1911  loss_dice_5: 0.4167  loss_ce_6: 0.04824  loss_mask_6: 0.1933  loss_dice_6: 0.3958  loss_ce_7: 0.06143  loss_mask_7: 0.1951  loss_dice_7: 0.3894  loss_ce_8: 0.07855  loss_mask_8: 0.194  loss_dice_8: 0.3819  time: 1.0572  data_time: 0.0583  lr: 7.4727e-06  max_mem: 18242M
[32m[04/07 01:43:04 d2.utils.events]: [0m eta: 0:01:43  iter: 899  total_loss: 7.186  loss_ce: 0.04144  loss_mask: 0.1854  loss_dice: 0.3999  loss_ce_0: 0.5489  loss_mask_0: 0.1885  loss_dice_0: 0.3836  loss_ce_1: 0.07092  loss_mask_1: 0.1937  loss_dice_1: 0.4012  loss_ce_2: 0.0573  loss_mask_2: 0.1856  loss_dice_2: 0.4095  loss_ce_3: 0.04692  loss_mask_3: 0.1858  loss_dice_3: 0.39  loss_ce_4: 0.0451  loss_mask_4: 0.1851  loss_dice_4: 0.4024  loss_ce_5: 0.04099  loss_mask_5: 0.1857  loss_dice_5: 0.3925  loss_ce_6: 0.05359  loss_mask_6: 0.1844  loss_dice_6: 0.3847  loss_ce_7: 0.04095  loss_mask_7: 0.1853  loss_dice_7: 0.3881  loss_ce_8: 0.03574  loss_mask_8: 0.1837  loss_dice_8: 0.4078  time: 1.0566  data_time: 0.0603  lr: 6.3513e-06  max_mem: 18242M
[32m[04/07 01:43:25 d2.utils.events]: [0m eta: 0:01:22  iter: 919  total_loss: 7.286  loss_ce: 0.03351  loss_mask: 0.1887  loss_dice: 0.4073  loss_ce_0: 0.564  loss_mask_0: 0.1986  loss_dice_0: 0.4328  loss_ce_1: 0.09395  loss_mask_1: 0.1912  loss_dice_1: 0.42  loss_ce_2: 0.08736  loss_mask_2: 0.1881  loss_dice_2: 0.4244  loss_ce_3: 0.07367  loss_mask_3: 0.1878  loss_dice_3: 0.4028  loss_ce_4: 0.06443  loss_mask_4: 0.1888  loss_dice_4: 0.4006  loss_ce_5: 0.05594  loss_mask_5: 0.1882  loss_dice_5: 0.4065  loss_ce_6: 0.0425  loss_mask_6: 0.1868  loss_dice_6: 0.3961  loss_ce_7: 0.03549  loss_mask_7: 0.1887  loss_dice_7: 0.4067  loss_ce_8: 0.05227  loss_mask_8: 0.188  loss_dice_8: 0.4309  time: 1.0561  data_time: 0.0661  lr: 5.2072e-06  max_mem: 18242M
[32m[04/07 01:43:45 d2.utils.events]: [0m eta: 0:01:01  iter: 939  total_loss: 6.761  loss_ce: 0.04045  loss_mask: 0.166  loss_dice: 0.3787  loss_ce_0: 0.5718  loss_mask_0: 0.1748  loss_dice_0: 0.3941  loss_ce_1: 0.05695  loss_mask_1: 0.1685  loss_dice_1: 0.3829  loss_ce_2: 0.04942  loss_mask_2: 0.1679  loss_dice_2: 0.3951  loss_ce_3: 0.04361  loss_mask_3: 0.1662  loss_dice_3: 0.3785  loss_ce_4: 0.04073  loss_mask_4: 0.1659  loss_dice_4: 0.3932  loss_ce_5: 0.04655  loss_mask_5: 0.1658  loss_dice_5: 0.3777  loss_ce_6: 0.06307  loss_mask_6: 0.1646  loss_dice_6: 0.3702  loss_ce_7: 0.0498  loss_mask_7: 0.1659  loss_dice_7: 0.3892  loss_ce_8: 0.03701  loss_mask_8: 0.1646  loss_dice_8: 0.3832  time: 1.0556  data_time: 0.0532  lr: 4.0343e-06  max_mem: 18242M
[32m[04/07 01:44:06 d2.utils.events]: [0m eta: 0:00:41  iter: 959  total_loss: 8.167  loss_ce: 0.05547  loss_mask: 0.2083  loss_dice: 0.3741  loss_ce_0: 0.6108  loss_mask_0: 0.2113  loss_dice_0: 0.3968  loss_ce_1: 0.1264  loss_mask_1: 0.2022  loss_dice_1: 0.3932  loss_ce_2: 0.08473  loss_mask_2: 0.2042  loss_dice_2: 0.3892  loss_ce_3: 0.09321  loss_mask_3: 0.2009  loss_dice_3: 0.398  loss_ce_4: 0.08537  loss_mask_4: 0.201  loss_dice_4: 0.3893  loss_ce_5: 0.08163  loss_mask_5: 0.2022  loss_dice_5: 0.3813  loss_ce_6: 0.0575  loss_mask_6: 0.2077  loss_dice_6: 0.3766  loss_ce_7: 0.1042  loss_mask_7: 0.202  loss_dice_7: 0.3868  loss_ce_8: 0.06198  loss_mask_8: 0.1985  loss_dice_8: 0.3916  time: 1.0550  data_time: 0.0628  lr: 2.8215e-06  max_mem: 18242M
[32m[04/07 01:44:27 d2.utils.events]: [0m eta: 0:00:20  iter: 979  total_loss: 7.221  loss_ce: 0.05647  loss_mask: 0.1894  loss_dice: 0.3816  loss_ce_0: 0.547  loss_mask_0: 0.1968  loss_dice_0: 0.4136  loss_ce_1: 0.09672  loss_mask_1: 0.1816  loss_dice_1: 0.381  loss_ce_2: 0.07834  loss_mask_2: 0.1866  loss_dice_2: 0.3823  loss_ce_3: 0.07152  loss_mask_3: 0.1878  loss_dice_3: 0.3772  loss_ce_4: 0.08754  loss_mask_4: 0.1814  loss_dice_4: 0.3837  loss_ce_5: 0.06941  loss_mask_5: 0.1826  loss_dice_5: 0.3723  loss_ce_6: 0.0492  loss_mask_6: 0.188  loss_dice_6: 0.3785  loss_ce_7: 0.07202  loss_mask_7: 0.1902  loss_dice_7: 0.39  loss_ce_8: 0.05449  loss_mask_8: 0.1874  loss_dice_8: 0.3793  time: 1.0543  data_time: 0.0498  lr: 1.5451e-06  max_mem: 18242M
[32m[04/07 01:44:47 fvcore.common.checkpoint]: [0mSaving checkpoint to ./output/swin_large/train_net_ignore_1/model_final.pth
train_list /home/fsun/segfusion/lists/replica/lisa_val_small.txt
train_list /home/fsun/segfusion/lists/replica/lisa_val_small.txt
/home/fsun/.conda/envs/m2f/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/home/fsun/.conda/envs/m2f/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
train_list /home/fsun/segfusion/lists/replica/lisa_val_small.txt
train_list /home/fsun/segfusion/lists/replica/lisa_val_small.txt
/home/fsun/.conda/envs/m2f/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/home/fsun/.conda/envs/m2f/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
train_list /home/fsun/segfusion/lists/replica/lisa_val_small.txt
train_list /home/fsun/segfusion/lists/replica/lisa_val_small.txt
/home/fsun/.conda/envs/m2f/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/home/fsun/.conda/envs/m2f/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
[32m[04/07 01:44:55 d2.utils.events]: [0m eta: 0:00:00  iter: 999  total_loss: 7.283  loss_ce: 0.06339  loss_mask: 0.1859  loss_dice: 0.4199  loss_ce_0: 0.5669  loss_mask_0: 0.199  loss_dice_0: 0.4236  loss_ce_1: 0.09038  loss_mask_1: 0.188  loss_dice_1: 0.4081  loss_ce_2: 0.06482  loss_mask_2: 0.186  loss_dice_2: 0.3994  loss_ce_3: 0.05286  loss_mask_3: 0.187  loss_dice_3: 0.3913  loss_ce_4: 0.06151  loss_mask_4: 0.1869  loss_dice_4: 0.3917  loss_ce_5: 0.06496  loss_mask_5: 0.186  loss_dice_5: 0.4057  loss_ce_6: 0.07735  loss_mask_6: 0.1881  loss_dice_6: 0.3969  loss_ce_7: 0.05873  loss_mask_7: 0.1851  loss_dice_7: 0.3951  loss_ce_8: 0.05953  loss_mask_8: 0.1886  loss_dice_8: 0.401  time: 1.0539  data_time: 0.0606  lr: 9.9763e-08  max_mem: 18242M
[32m[04/07 01:44:55 d2.engine.hooks]: [0mOverall training speed: 998 iterations in 0:17:31 (1.0539 s / it)
[32m[04/07 01:44:55 d2.engine.hooks]: [0mTotal training time: 0:17:44 (0:00:12 on hooks)
train_list /home/fsun/segfusion/lists/replica/lisa_val_small.txt
[32m[04/07 01:44:55 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[32m[04/07 01:44:55 d2.data.common]: [0mSerializing 200 elements to byte tensors and concatenating them all ...
[32m[04/07 01:44:55 d2.data.common]: [0mSerialized dataset takes 0.04 MiB
train_list /home/fsun/segfusion/lists/replica/lisa_val_small.txt
[32m[04/07 01:44:55 d2.evaluation.evaluator]: [0mStart inference on 50 batches
/home/fsun/.conda/envs/m2f/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/home/fsun/.conda/envs/m2f/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
[32m[04/07 01:45:00 d2.evaluation.evaluator]: [0mInference done 11/50. Dataloading: 0.0017 s/iter. Inference: 0.1335 s/iter. Eval: 0.0314 s/iter. Total: 0.1666 s/iter. ETA=0:00:06
[32m[04/07 01:45:05 d2.evaluation.evaluator]: [0mInference done 44/50. Dataloading: 0.0026 s/iter. Inference: 0.1293 s/iter. Eval: 0.0222 s/iter. Total: 0.1541 s/iter. ETA=0:00:00
[32m[04/07 01:45:06 d2.evaluation.evaluator]: [0mTotal inference time: 0:00:07.215202 (0.160338 s / iter per device, on 4 devices)
[32m[04/07 01:45:06 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:00:05 (0.127829 s / iter per device, on 4 devices)
[32m[04/07 01:45:07 d2.evaluation.sem_seg_evaluation]: [0mOrderedDict([('sem_seg', {'mIoU': 17.58057801190023, 'fwIoU': 26.265115356503838, 'IoU-undefined': nan, 'IoU-beanbag': nan, 'IoU-bed': nan, 'IoU-bike': nan, 'IoU-book': nan, 'IoU-cabinet': nan, 'IoU-ceiling': 73.84638406704033, 'IoU-chair': 66.57433490200184, 'IoU-clothing': nan, 'IoU-container': 21.77686045783204, 'IoU-curtain': 0.2718749891790718, 'IoU-cushion': nan, 'IoU-door': 51.45391686028523, 'IoU-floor': 1.7580581799404453, 'IoU-indoor-plant': 0.0, 'IoU-lamp': 94.95552302668618, 'IoU-refrigerator': nan, 'IoU-rug': 0.0, 'IoU-shelf': 0.0, 'IoU-sink': nan, 'IoU-sofa': 40.6264759626627, 'IoU-stair': nan, 'IoU-structure': 0.0013719646772781175, 'IoU-table': 38.87484933878692, 'IoU-tv-screen': 19.81850672666846, 'IoU-tv-stand': nan, 'IoU-wall': 28.91402266457771, 'IoU-wall-cabinet': nan, 'IoU-wall-decoration': 0.6422711571675301, 'IoU-window': nan, 'mACC': 49.65247190481744, 'pACC': 32.38065897987259, 'ACC-undefined': nan, 'ACC-beanbag': nan, 'ACC-bed': nan, 'ACC-bike': nan, 'ACC-book': nan, 'ACC-cabinet': nan, 'ACC-ceiling': 95.03104502696016, 'ACC-chair': 93.24406730524116, 'ACC-clothing': nan, 'ACC-container': 57.450398810093326, 'ACC-curtain': 0.306280230056752, 'ACC-cushion': nan, 'ACC-door': 87.94573643410853, 'ACC-floor': 92.65607426299366, 'ACC-indoor-plant': 0.0, 'ACC-lamp': 96.9867740080506, 'ACC-refrigerator': nan, 'ACC-rug': 0.0, 'ACC-shelf': 0.0, 'ACC-sink': nan, 'ACC-sofa': 42.4098532925859, 'ACC-stair': nan, 'ACC-structure': 0.005225277621271878, 'ACC-table': 95.03130677568622, 'ACC-tv-screen': 98.47739287714845, 'ACC-tv-stand': nan, 'ACC-wall': 31.891736254779595, 'ACC-wall-cabinet': nan, 'ACC-wall-decoration': 3.003659921753397, 'ACC-window': nan})])
[32m[04/07 01:45:07 d2.engine.defaults]: [0mEvaluation results for replica_sem_seg_val in csv format:
[32m[04/07 01:45:07 d2.evaluation.testing]: [0mcopypaste: Task: sem_seg
[32m[04/07 01:45:07 d2.evaluation.testing]: [0mcopypaste: mIoU,fwIoU,mACC,pACC
[32m[04/07 01:45:07 d2.evaluation.testing]: [0mcopypaste: 17.5806,26.2651,49.6525,32.3807
